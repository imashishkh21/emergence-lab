# Phase 2 Progress: Evolutionary Pressure

## Session Start
Date: 2026-02-01
Previous Phase: Phase 1 COMPLETE — field ablation showed Normal (63.36) >> Zeroed (22.88)

## Key Technical Decisions

1. **JAX Static Shapes**: Use fixed max_agents array with alive mask instead of dynamic population
2. **Weight Inheritance**: Per-agent params with vmapped forward pass
3. **Reproduction**: Action 5 triggers reproduction if energy >= threshold
4. **Death**: Energy <= 0 sets alive = False, slot reusable

---

## Task Log

### US-001: Add Evolution Config ✓
**What:** Added `EvolutionConfig` dataclass and `evolution` field to main `Config`.
**Decisions:** Used same dataclass pattern as existing configs. All defaults match PRD spec.
**Files changed:**
- `src/configs.py` — Added `EvolutionConfig` dataclass, added `evolution` field to `Config`, updated `from_yaml` to parse evolution section
- `configs/phase2.yaml` — Created with all Phase 2 settings including evolution config
**Issues:** None. All 56 tests pass, mypy clean.

---

### US-002: Extend EnvState with Energy and Alive Mask ✓
**What:** Added evolution tracking fields to `EnvState` and updated `agent_positions` from `(num_agents, 2)` to `(max_agents, 2)` with padding for dead agents.
**Decisions:**
- `agent_positions` padded to `(max_agents, 2)` — dead slots get `(0, 0)`.
- `agent_energy` is `float32` for smooth gradient-friendly math later.
- `agent_alive` is `bool_` mask — True for first `num_agents`, False for rest.
- `agent_ids` starts at `[0, 1, ..., num_agents-1, -1, -1, ...]`.
- `agent_parent_ids` all `-1` initially (no parents for original agents).
- `next_agent_id` initialized to `num_agents` (scalar counter).
- `step()` pads incoming actions to `(max_agents,)` so dead agents get action 0 (stay).
- Dead agents masked out of movement, food collection, and field writes.
- `obs.py` slices `[:num_agents]` for observations (US-010 will generalize).
- `render.py` skips dead agents when drawing.
- `ablation.py` `_replace_field` updated to pass through all new fields.
**Files changed:**
- `src/environment/state.py` — Added 5 new fields to `EnvState`, updated `create_env_state`
- `src/environment/env.py` — Updated `reset()` and `step()` for `(max_agents, 2)` shapes and alive masking
- `src/environment/obs.py` — Slice `[:num_agents]` for active agents only
- `src/environment/render.py` — Skip dead agents when drawing
- `src/analysis/ablation.py` — Updated `_replace_field` to include new fields
- `tests/test_env.py` — Updated shape assertions for `max_agents`, added checks for new fields
**Issues:** None. All 56 tests pass, mypy clean.

---

### US-003: Update Environment Reset for Evolution ✓
**What:** Verified that `reset()` already correctly initializes all evolution state fields (done in US-002). Added value-level tests to ensure correctness beyond shape checks.
**Decisions:**
- The `reset()` implementation was already complete from US-002 — energy values, alive mask, agent IDs, parent IDs, next_agent_id, and dead slot positions were all initialized correctly.
- Added 3 new tests to `TestEnvReset` to verify actual values: `test_reset_evolution_energy_values`, `test_reset_evolution_ids`, `test_reset_dead_agent_positions`.
**Files changed:**
- `tests/test_env.py` — Added 3 tests verifying evolution field values (energy, IDs, dead positions)
**Issues:** None. All 59 tests pass, mypy clean.

---

### US-004: Implement Energy Drain Per Step ✓
**What:** Added energy drain logic to `step()` — alive agents lose `energy_per_step` each step, clamped to 0. Created `tests/test_energy.py` with 5 tests covering drain, alive-only masking, floor clamping, multi-step accumulation, and JIT compatibility.
**Decisions:**
- Used `jnp.where(agent_alive, max(energy - cost, 0), energy)` pattern — clean, JIT-friendly, no mutation.
- Energy drain happens after movement and food collection but before step counter advance (section 5 in step()).
- Dead agent slots (energy=0, alive=False) are untouched by drain.
**Files changed:**
- `src/environment/env.py` — Added energy drain logic in `step()`, renumbered subsequent sections
- `tests/test_energy.py` — Created with 5 tests in `TestEnergyDrain` class
**Issues:** None. All 64 tests pass, mypy clean.

---

### US-005: Implement Death from Starvation ✓
**What:** Added death-from-starvation logic to `step()` — agents with energy <= 0 after energy drain have `agent_alive` set to False. Death count is logged in the info dict.
**Decisions:**
- Death check happens immediately after energy drain (section 6 in step()), before step counter advance.
- Used `starved = state.agent_alive & (new_energy <= 0)` pattern — only previously alive agents can die.
- `new_alive = state.agent_alive & ~starved` — clean boolean masking, no mutation.
- Dead agents remain in arrays (positions, IDs preserved) but are masked out of movement and actions on subsequent steps.
- Added `deaths_this_step` to info dict as `jnp.int32` count.
- Added 7 tests: death on zero energy, death count in info, no deaths with enough energy, dead agents stay in arrays, dead agents don't move, partial death (mixed energy levels), JIT compatibility.
**Files changed:**
- `src/environment/env.py` — Added death-from-starvation logic (section 6), updated `new_state` to use `new_alive`, added `deaths_this_step` to info dict, renumbered subsequent sections
- `tests/test_energy.py` — Added `TestDeath` class with 7 tests
**Issues:** None. All 71 tests pass, mypy clean.

---

### US-006: Implement Food Restores Energy ✓
**What:** Food collection now adds `food_energy` to the closest alive agent's energy, capped at `max_energy`. Rewards changed from shared team reward to individual energy-gained per agent.
**Decisions:**
- Used Chebyshev distance to determine closest alive agent per food item. Ties broken by lowest agent index (via `jnp.argmin`).
- One-hot encoding + sum pattern to compute per-agent energy gain from potentially multiple food items — clean, JIT-friendly, no loops.
- Food energy is applied before energy drain: agent gains food energy, then loses `energy_per_step`.
- Energy capped at `max_energy` before drain.
- Rewards changed from shared (`num_collected` broadcast) to individual (`energy_gained` per agent, sliced to `num_agents`).
- Updated existing energy drain and death tests to set `food_energy=0` so random food proximity doesn't interfere with their assertions.
**Files changed:**
- `src/environment/env.py` — Rewrote food collection section (section 2) to track closest agent per food, compute per-agent energy gain, cap at max_energy. Updated energy drain (section 5) to use `energy_after_food`. Changed reward computation (section 3) to individual energy-gained.
- `tests/test_energy.py` — Added `_make_state_with_positions` helper and `TestFoodEnergy` class with 8 tests: basic energy gain, max energy cap, closest-agent selection, dead agents can't collect, multiple food items, individual rewards, no food nearby, JIT compatibility. Fixed existing drain/death tests to disable food energy.
**Issues:** None. All 79 tests pass, mypy clean.

---
