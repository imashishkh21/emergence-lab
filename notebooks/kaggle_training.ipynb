{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emergence Lab - Kaggle Training\n",
    "\n",
    "Autonomous training notebook for running emergence experiments on Kaggle GPUs.\n",
    "\n",
    "**What this does:**\n",
    "1. Installs JAX with CUDA support and verifies GPU access\n",
    "2. Clones the repo and installs dependencies\n",
    "3. Configures hyperparameters\n",
    "4. Resumes from checkpoint if available, otherwise starts fresh\n",
    "5. Runs training with progress display and periodic checkpointing\n",
    "\n",
    "**Usage:**\n",
    "- Upload to Kaggle as a new notebook\n",
    "- Enable GPU accelerator (Settings > Accelerator > GPU T4 x2 or P100)\n",
    "- Run all cells\n",
    "- Checkpoints are saved to `/kaggle/working/checkpoints/`\n",
    "- Download checkpoints after the run completes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install JAX with CUDA and Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install JAX with CUDA and verify GPU\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install JAX with CUDA 12 support (Kaggle provides CUDA 12.x)\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "    \"jax[cuda12]\",\n",
    "])\n",
    "\n",
    "# Verify GPU is available\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")\n",
    "\n",
    "gpu_devices = [d for d in jax.devices() if d.device_kind == \"gpu\"]\n",
    "if gpu_devices:\n",
    "    print(f\"GPU available: {gpu_devices[0].device_kind} - {gpu_devices[0]}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU found! Training will be slow on CPU.\")\n",
    "    print(\"Make sure GPU accelerator is enabled in Kaggle notebook settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Clone Repo and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Clone repo and install dependencies\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "REPO_URL = \"https://github.com/ashishkej/emergence-lab.git\"  # UPDATE THIS\n",
    "REPO_DIR = \"/kaggle/working/emergence-lab\"\n",
    "BRANCH = \"main\"\n",
    "\n",
    "# Clone or update repo\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f\"Repo exists at {REPO_DIR}, pulling latest...\")\n",
    "    subprocess.check_call([\"git\", \"-C\", REPO_DIR, \"pull\", \"origin\", BRANCH])\n",
    "else:\n",
    "    print(f\"Cloning repo to {REPO_DIR}...\")\n",
    "    subprocess.check_call([\n",
    "        \"git\", \"clone\", \"--branch\", BRANCH, \"--depth\", \"1\", REPO_URL, REPO_DIR,\n",
    "    ])\n",
    "\n",
    "# Install the package (skip JAX since we installed CUDA version above)\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "    \"-e\", REPO_DIR,\n",
    "    \"--no-deps\",  # Skip deps to avoid overwriting CUDA JAX\n",
    "])\n",
    "\n",
    "# Install non-JAX dependencies separately\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "    \"flax>=0.8.0\", \"optax>=0.1.7\", \"chex>=0.1.8\",\n",
    "    \"numpy>=1.24.0\", \"scipy>=1.10.0\", \"scikit-learn>=1.3.0\",\n",
    "    \"pyyaml>=6.0\", \"tqdm>=4.65.0\", \"matplotlib>=3.7.0\",\n",
    "    \"wandb>=0.16.0\", \"imageio>=2.31.0\", \"imageio-ffmpeg>=0.4.8\",\n",
    "    \"tyro>=0.6.0\", \"msgpack>=1.0.0\",\n",
    "])\n",
    "\n",
    "# Add repo to Python path\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "# Verify import\n",
    "from src.configs import Config\n",
    "print(f\"\\nEmergence Lab imported successfully from {REPO_DIR}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configuration\n",
    "#\n",
    "# Adjust these hyperparameters for your experiment.\n",
    "# Defaults are tuned for a Kaggle T4 GPU (~16GB VRAM, 30hr/week budget).\n",
    "\n",
    "from src.configs import (\n",
    "    Config,\n",
    "    EnvConfig,\n",
    "    FieldConfig,\n",
    "    AgentConfig,\n",
    "    TrainConfig,\n",
    "    LogConfig,\n",
    "    EvolutionConfig,\n",
    "    SpecializationConfig,\n",
    "    AnalysisConfig,\n",
    ")\n",
    "\n",
    "# --- Paths ---\n",
    "CHECKPOINT_DIR = \"/kaggle/working/checkpoints\"\n",
    "RESUME_FROM = None  # Set to checkpoint path to resume, e.g.:\n",
    "# RESUME_FROM = \"/kaggle/working/checkpoints/latest.pkl\"\n",
    "\n",
    "# --- Experiment Config ---\n",
    "config = Config(\n",
    "    env=EnvConfig(\n",
    "        grid_size=20,\n",
    "        num_agents=8,\n",
    "        num_food=20,       # More food for robust population\n",
    "        max_steps=500,\n",
    "    ),\n",
    "    field=FieldConfig(\n",
    "        num_channels=4,\n",
    "        diffusion_rate=0.1,\n",
    "        decay_rate=0.05,\n",
    "    ),\n",
    "    agent=AgentConfig(\n",
    "        hidden_dims=(64, 64),\n",
    "    ),\n",
    "    train=TrainConfig(\n",
    "        seed=42,\n",
    "        total_steps=10_000_000,  # 10M steps (~8-12 hours on T4)\n",
    "        num_envs=32,\n",
    "        num_steps=128,\n",
    "        learning_rate=3e-4,\n",
    "        resume_from=RESUME_FROM,\n",
    "    ),\n",
    "    log=LogConfig(\n",
    "        wandb=False,           # Set True if you have W&B configured\n",
    "        save_interval=100_000, # Save every 100k steps\n",
    "        checkpoint_dir=CHECKPOINT_DIR,\n",
    "        server=False,          # No dashboard server on Kaggle\n",
    "    ),\n",
    "    analysis=AnalysisConfig(\n",
    "        emergence_check_interval=10_000,\n",
    "        specialization_check_interval=20_000,\n",
    "    ),\n",
    "    evolution=EvolutionConfig(\n",
    "        enabled=True,\n",
    "        starting_energy=200,   # Survival-friendly\n",
    "        food_energy=100,\n",
    "        reproduce_threshold=120,\n",
    "        reproduce_cost=50,\n",
    "        mutation_std=0.01,\n",
    "        max_agents=32,\n",
    "    ),\n",
    "    specialization=SpecializationConfig(\n",
    "        diversity_bonus=0.1,   # Encourage unique weights\n",
    "        niche_pressure=0.05,   # Penalize identical strategies\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Grid: {config.env.grid_size}x{config.env.grid_size}\")\n",
    "print(f\"  Agents: {config.env.num_agents} (max: {config.evolution.max_agents})\")\n",
    "print(f\"  Food: {config.env.num_food}\")\n",
    "print(f\"  Total steps: {config.train.total_steps:,}\")\n",
    "print(f\"  Save interval: {config.log.save_interval:,}\")\n",
    "print(f\"  Checkpoint dir: {config.log.checkpoint_dir}\")\n",
    "print(f\"  Resume from: {config.train.resume_from or 'None (fresh start)'}\")\n",
    "print(f\"  Evolution: {'enabled' if config.evolution.enabled else 'disabled'}\")\n",
    "print(f\"  Diversity bonus: {config.specialization.diversity_bonus}\")\n",
    "print(f\"  Niche pressure: {config.specialization.niche_pressure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Resume or Start Fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Resume-or-start logic\n",
    "#\n",
    "# Automatically detects existing checkpoints and resumes if available.\n",
    "# If no checkpoint exists, starts fresh training.\n",
    "\n",
    "import os\n",
    "\n",
    "# Check for existing checkpoints\n",
    "latest_checkpoint = os.path.join(CHECKPOINT_DIR, \"latest.pkl\")\n",
    "\n",
    "if config.train.resume_from is not None:\n",
    "    # Explicit resume path set in Cell 3\n",
    "    if os.path.exists(config.train.resume_from):\n",
    "        print(f\"Will resume from explicit path: {config.train.resume_from}\")\n",
    "    else:\n",
    "        print(f\"WARNING: Resume path not found: {config.train.resume_from}\")\n",
    "        print(\"Will start fresh training.\")\n",
    "        config.train.resume_from = None\n",
    "elif os.path.exists(latest_checkpoint):\n",
    "    # Auto-detect latest checkpoint\n",
    "    config.train.resume_from = latest_checkpoint\n",
    "    print(f\"Found existing checkpoint: {latest_checkpoint}\")\n",
    "    print(\"Will resume from latest checkpoint.\")\n",
    "    \n",
    "    # Show checkpoint info\n",
    "    from src.training.checkpointing import load_checkpoint\n",
    "    ckpt = load_checkpoint(latest_checkpoint)\n",
    "    print(f\"  Checkpoint step: {ckpt.get('step', 'unknown')}\")\n",
    "    remaining = config.train.total_steps - ckpt.get('step', 0)\n",
    "    print(f\"  Remaining steps: {remaining:,}\")\n",
    "    if remaining <= 0:\n",
    "        print(\"  Training already complete! Increase total_steps to continue.\")\n",
    "else:\n",
    "    print(\"No existing checkpoint found. Starting fresh training.\")\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    print(f\"Checkpoint directory created: {CHECKPOINT_DIR}\")\n",
    "\n",
    "print(f\"\\nReady to train for {config.train.total_steps:,} total steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run training with progress display\n",
    "#\n",
    "# This cell runs the full training loop. Checkpoints are saved\n",
    "# every save_interval steps and on completion.\n",
    "#\n",
    "# If the Kaggle session times out, re-run the notebook.\n",
    "# Cell 4 will automatically detect the latest checkpoint and resume.\n",
    "\n",
    "import time\n",
    "\n",
    "from src.training.train import train\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Checkpoints will be saved to: {config.log.checkpoint_dir}\")\n",
    "print(f\"Save interval: every {config.log.save_interval:,} steps\")\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    final_state = train(config)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTraining complete! Elapsed: {elapsed / 3600:.1f} hours\")\n",
    "except KeyboardInterrupt:\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTraining interrupted after {elapsed / 3600:.1f} hours\")\n",
    "    print(\"Emergency checkpoint should have been saved.\")\n",
    "except Exception as e:\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTraining failed after {elapsed / 3600:.1f} hours: {e}\")\n",
    "    print(\"Check the latest checkpoint in the checkpoint directory.\")\n",
    "    raise\n",
    "\n",
    "# List saved checkpoints\n",
    "import glob\n",
    "checkpoints = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"step_*.pkl\")))\n",
    "print(f\"\\nSaved checkpoints ({len(checkpoints)}):\")\n",
    "for cp in checkpoints:\n",
    "    size_mb = os.path.getsize(cp) / (1024 * 1024)\n",
    "    print(f\"  {os.path.basename(cp)} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nDownload checkpoints from: {CHECKPOINT_DIR}\")\n",
    "print(\"Use Kaggle Output tab or kaggle_download.sh to retrieve them.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}