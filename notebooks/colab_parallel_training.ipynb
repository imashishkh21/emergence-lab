{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emergence Lab - Patch Scaling Validation\n",
    "\n",
    "This notebook validates the **patch throughput scaling** fix for coordination collapse.\n",
    "\n",
    "**New in this version:**\n",
    "- `patch_scaling_enabled = True` - rewards scale by âˆšn/n at delivery\n",
    "- `Ch1 OFF` - territory channel disabled, only recruitment trails\n",
    "- 2M steps for quick validation (change to 10M for full experiment)\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "| Step | What to do |\n",
    "|------|------------|\n",
    "| **0** | **Run TEST MODE first** (cell after setup) |\n",
    "| 1 | If test passes, set `TEST_MODE = False`, then `BATCH_NUMBER = 0` |\n",
    "| 2 | Change `BATCH_NUMBER = 1`, run again |\n",
    "| ... | Continue batches 2-9 |\n",
    "| 11 | Set `FIELD_ENABLED = False`, `BATCH_NUMBER = 0` |\n",
    "| ... | Continue batches 1-9 |\n",
    "\n",
    "**Config**: 64 max agents, 32x32 grid, 40 food (proven UTOPIA config)\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Open this notebook in Google Colab\n",
    "2. Runtime > Change runtime type > **TPU v5e** (or v6e) + **High-RAM**\n",
    "3. Run setup cells (1-4)\n",
    "4. **Run TEST MODE cell first** - verify it passes before full training\n",
    "5. Then run full training cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup\n",
    "\n",
    "Mount Google Drive, clone the repo, and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory\n",
    "import os\n",
    "CHECKPOINT_BASE = '/content/drive/MyDrive/emergence-lab'\n",
    "os.makedirs(CHECKPOINT_BASE, exist_ok=True)\n",
    "print(f\"Checkpoint base: {CHECKPOINT_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repo if not already present\nREPO_DIR = '/content/emergence-lab'\n\n# âš ï¸ CHANGE THIS to your GitHub username\nGITHUB_USERNAME = \"imashishkh\"\n\nif not os.path.exists(REPO_DIR):\n    !git clone https://github.com/{GITHUB_USERNAME}/emergence-lab.git {REPO_DIR}\nelse:\n    print(f\"Repo already exists at {REPO_DIR}\")\n    # Pull latest changes\n    !cd {REPO_DIR} && git pull\n\n# Change to repo directory\nos.chdir(REPO_DIR)\nprint(f\"Working directory: {os.getcwd()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -e \".[dev]\" -q\n",
    "\n",
    "# Verify JAX sees TPU\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")\n",
    "print(f\"Device count: {jax.device_count()}\")\n",
    "\n",
    "# Check if TPU is available\n",
    "if 'tpu' in str(jax.devices()[0]).lower():\n",
    "    print(\"TPU detected!\")\n",
    "else:\n",
    "    print(\"WARNING: TPU not detected. Training will be slower on GPU/CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## âš ï¸ TEST MODE - Run This First!\n\nBefore running the full experiment, do a quick test to verify everything works.\nThis uses ~1% of compute and catches errors early.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# ðŸ§ª TEST RUN - Verify parallel training works before full experiment\n",
    "# =============================================================================\n",
    "# This runs 2 seeds for 100K steps (~1-2 minutes) to catch errors early.\n",
    "# If this succeeds, the full experiment should work.\n",
    "\n",
    "TEST_MODE = True  # Set to False to skip test and go straight to full training\n",
    "\n",
    "if TEST_MODE:\n",
    "    print(\"=\"*60)\n",
    "    print(\"ðŸ§ª TEST MODE: Running quick verification...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    from src.configs import Config\n",
    "    from src.training.parallel_train import ParallelTrainer\n",
    "    import time\n",
    "    \n",
    "    # Minimal test config - MATCHES PROVEN 64-AGENT CONFIG\n",
    "    test_config = Config()\n",
    "    test_config.env.grid_size = 32        # Larger grid for 64 agents\n",
    "    test_config.env.num_agents = 16       # Starting population\n",
    "    test_config.env.num_food = 40         # More food for 64 agents\n",
    "    test_config.evolution.enabled = True\n",
    "    test_config.evolution.max_agents = 64 # PROVEN: 64 agents achieved UTOPIA\n",
    "    test_config.evolution.starting_energy = 200\n",
    "    test_config.evolution.food_energy = 100\n",
    "    test_config.evolution.reproduce_threshold = 120\n",
    "    test_config.evolution.reproduce_cost = 40  # PROVEN: 40 not 50\n",
    "\n",
    "    # === PATCH SCALING VALIDATION ===\n",
    "    test_config.nest.patch_scaling_enabled = True\n",
    "    test_config.nest.patch_radius = 2\n",
    "    test_config.nest.patch_n_cap = 6\n",
    "\n",
    "    # Ch1 OFF (territory channel disabled per ChatGPT recommendation)\n",
    "    test_config.field.channel_decay_rates = (0.05, 1.0, 0.0, 0.0)\n",
    "    test_config.train.num_envs = 32\n",
    "    test_config.train.num_steps = 128\n",
    "    test_config.log.wandb = False\n",
    "    \n",
    "    # Test parameters: 2 seeds, 100K steps\n",
    "    TEST_STEPS = 100_000\n",
    "    TEST_SEEDS = 2\n",
    "    TEST_CHECKPOINT_DIR = f'{CHECKPOINT_BASE}/test_run'\n",
    "    \n",
    "    steps_per_iter = 32 * 128 * 64  # num_envs * num_steps * max_agents (64!)\n",
    "    test_iterations = max(1, TEST_STEPS // steps_per_iter)  # At least 1 iteration\n",
    "    \n",
    "    print(f\"Test config:\")\n",
    "    print(f\"  Seeds: {TEST_SEEDS}\")\n",
    "    print(f\"  Steps: {TEST_STEPS:,}\")\n",
    "    print(f\"  Iterations: {test_iterations}\")\n",
    "    print(f\"  Grid size: 32\")\n",
    "    print(f\"  Max agents: 64 (PROVEN CONFIG)\")\n",
    "    print(f\"  Checkpoint dir: {TEST_CHECKPOINT_DIR}\")\n",
    "    print()\n",
    "    \n",
    "    # Run test\n",
    "    try:\n",
    "        test_trainer = ParallelTrainer(\n",
    "            config=test_config,\n",
    "            num_seeds=TEST_SEEDS,\n",
    "            seed_ids=[100, 101],  # Use different IDs to avoid conflicts\n",
    "            checkpoint_dir=TEST_CHECKPOINT_DIR,\n",
    "            master_seed=9999,\n",
    "        )\n",
    "        \n",
    "        t0 = time.time()\n",
    "        test_metrics = test_trainer.train(\n",
    "            num_iterations=test_iterations,\n",
    "            checkpoint_interval_minutes=60,  # Won't trigger in short test\n",
    "            resume=False,\n",
    "            print_interval=5,\n",
    "        )\n",
    "        elapsed = time.time() - t0\n",
    "        \n",
    "        print()\n",
    "        print(\"=\"*60)\n",
    "        print(\"âœ… TEST PASSED!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Time: {elapsed:.1f}s\")\n",
    "        print(f\"Final reward: {test_metrics.get('mean_reward', ['N/A'])}\")\n",
    "        print()\n",
    "        print(\"The parallel training code works. You can now run the full experiment.\")\n",
    "        print(\"Set TEST_MODE = False in this cell and run the cells below.\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(\"=\"*60)\n",
    "        print(\"âŒ TEST FAILED!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Error: {e}\")\n",
    "        print()\n",
    "        print(\"DO NOT proceed with full training until this is fixed.\")\n",
    "        print(\"Share the error message to debug.\")\n",
    "        print(\"=\"*60)\n",
    "        raise e\n",
    "\n",
    "else:\n",
    "    print(\"TEST_MODE = False, skipping test.\")\n",
    "    print(\"Proceeding to full training configuration...\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration\n",
    "\n",
    "Configure which seeds to run and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these values as needed\n",
    "# =============================================================================\n",
    "\n",
    "# Which batch of seeds to run (0-9 for 30 total seeds with 3 seeds per batch)\n",
    "# Batch 0: seeds 0-2\n",
    "# Batch 1: seeds 3-5\n",
    "# Batch 2: seeds 6-8\n",
    "# Batch 3: seeds 9-11\n",
    "# Batch 4: seeds 12-14\n",
    "# Batch 5: seeds 15-17\n",
    "# Batch 6: seeds 18-20\n",
    "# Batch 7: seeds 21-23\n",
    "# Batch 8: seeds 24-26\n",
    "# Batch 9: seeds 27-29\n",
    "BATCH_NUMBER = 0  # Change this for each Colab session\n",
    "\n",
    "# Seeds per batch (3 for 64-agent config to avoid OOM)\n",
    "# With 64 max_agents, 3 seeds is safer than 5\n",
    "SEEDS_PER_BATCH = 3\n",
    "\n",
    "# Compute seed IDs for this batch\n",
    "SEED_IDS = list(range(BATCH_NUMBER * SEEDS_PER_BATCH, (BATCH_NUMBER + 1) * SEEDS_PER_BATCH))\n",
    "\n",
    "# Training parameters\n",
    "TOTAL_STEPS = 2_000_000  # 2M steps for validation (change to 10M for full experiment)\n",
    "NUM_ENVS = 32  # Parallel environments per seed\n",
    "NUM_STEPS = 128  # Steps per rollout\n",
    "\n",
    "# Field ablation setting\n",
    "# Set to True for normal training, False for ablation (no field)\n",
    "FIELD_ENABLED = True\n",
    "\n",
    "# Checkpoint directory - SEPARATE for field_on vs field_off\n",
    "CONDITION_NAME = \"patch_scaling_validation\"  # Separate folder for this experiment\n",
    "CHECKPOINT_DIR = f'{CHECKPOINT_BASE}/{CONDITION_NAME}/batch_{BATCH_NUMBER}'\n",
    "\n",
    "# Checkpoint interval in minutes\n",
    "CHECKPOINT_INTERVAL_MINUTES = 30\n",
    "\n",
    "# Resume from existing checkpoints?\n",
    "RESUME = True\n",
    "\n",
    "# =============================================================================\n",
    "# Print configuration summary\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"Configuration Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Condition: {CONDITION_NAME}\")\n",
    "print(f\"Batch number: {BATCH_NUMBER}\")\n",
    "print(f\"Seed IDs: {SEED_IDS}\")\n",
    "print(f\"Seeds per batch: {SEEDS_PER_BATCH} (3 for 64-agent safety)\")\n",
    "print(f\"Total steps per seed: {TOTAL_STEPS:,}\")\n",
    "print(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\n",
    "print(f\"Checkpoint interval: {CHECKPOINT_INTERVAL_MINUTES} minutes\")\n",
    "print(f\"Field enabled: {FIELD_ENABLED}\")\n",
    "print(f\"Resume from checkpoints: {RESUME}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build configuration\n",
    "from src.configs import Config, EnvConfig, EvolutionConfig, FieldConfig\n",
    "\n",
    "# Start with default config\n",
    "config = Config()\n",
    "\n",
    "# =============================================================================\n",
    "# PROVEN 64-AGENT CONFIG (from seeds 42-45 that achieved UTOPIA)\n",
    "# This exact config produced:\n",
    "#   - Seed 44: UTOPIA (64 agents, reward 5.62)\n",
    "#   - Seed 43: THRIVING (62 agents, reward 5.36)\n",
    "#   - Emergence events detected in 3/4 seeds\n",
    "# =============================================================================\n",
    "config.env.grid_size = 32             # Larger grid for 64 agents (default 20)\n",
    "config.env.num_agents = 16            # Starting population (default 8)\n",
    "config.env.num_food = 40              # More food for 64 agents (default 10)\n",
    "\n",
    "config.evolution.enabled = True\n",
    "config.evolution.max_agents = 64      # PROVEN: 64 achieved UTOPIA\n",
    "config.evolution.starting_energy = 200  # Survival-friendly\n",
    "config.evolution.food_energy = 100    # High energy per food\n",
    "config.evolution.energy_per_step = 1  # Energy drain per step\n",
    "config.evolution.reproduce_threshold = 120  # Easier to reproduce\n",
    "config.evolution.reproduce_cost = 40  # PROVEN: 40 not 50!\n",
    "config.evolution.mutation_std = 0.01  # Standard mutation rate\n",
    "\n",
    "# === PATCH SCALING ===\n",
    "config.nest.patch_scaling_enabled = True\n",
    "config.nest.patch_radius = 2\n",
    "config.nest.patch_n_cap = 6\n",
    "\n",
    "# Ch1 OFF (territory channel disabled - only recruitment trails active)\n",
    "config.field.channel_decay_rates = (0.05, 1.0, 0.0, 0.0)\n",
    "\n",
    "# Training parameters\n",
    "config.train.total_steps = TOTAL_STEPS\n",
    "config.train.num_envs = NUM_ENVS\n",
    "config.train.num_steps = NUM_STEPS\n",
    "config.train.seed = 42  # Master seed (individual seeds are derived)\n",
    "\n",
    "# Field ablation (if disabled, zero out the field)\n",
    "if not FIELD_ENABLED:\n",
    "    # Zero out field by setting decay to 1.0 (field becomes zero before observation)\n",
    "    config.field.decay_rate = 1.0\n",
    "    config.field.diffusion_rate = 0.0\n",
    "    config.field.write_strength = 0.0\n",
    "\n",
    "# Logging (disable W&B for parallel training)\n",
    "config.log.wandb = False\n",
    "config.log.save_interval = 0  # We handle checkpointing ourselves\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PROVEN 64-AGENT CONFIG LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Grid size: {config.env.grid_size}\")\n",
    "print(f\"  Starting agents: {config.env.num_agents}\")\n",
    "print(f\"  Num food: {config.env.num_food}\")\n",
    "print(f\"  Max agents: {config.evolution.max_agents}\")\n",
    "print(f\"  Starting energy: {config.evolution.starting_energy}\")\n",
    "print(f\"  Food energy: {config.evolution.food_energy}\")\n",
    "print(f\"  Reproduce threshold: {config.evolution.reproduce_threshold}\")\n",
    "print(f\"  Reproduce cost: {config.evolution.reproduce_cost}\")\n",
    "print(f\"  Field channels: {config.field.num_channels}\")\n",
    "print(f\"  Field enabled: {FIELD_ENABLED}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Training\n",
    "\n",
    "Run parallel training with automatic checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.parallel_train import ParallelTrainer\n",
    "\n",
    "# Calculate number of iterations\n",
    "steps_per_iter = NUM_ENVS * NUM_STEPS * config.evolution.max_agents\n",
    "num_iterations = TOTAL_STEPS // steps_per_iter\n",
    "\n",
    "print(f\"Steps per iteration: {steps_per_iter:,}\")\n",
    "print(f\"Number of iterations: {num_iterations:,}\")\n",
    "print()\n",
    "\n",
    "# Create trainer\n",
    "trainer = ParallelTrainer(\n",
    "    config=config,\n",
    "    num_seeds=SEEDS_PER_BATCH,\n",
    "    seed_ids=SEED_IDS,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    master_seed=42 + BATCH_NUMBER * 1000,  # Different master seed per batch\n",
    ")\n",
    "\n",
    "# Run training\n",
    "metrics = trainer.train(\n",
    "    num_iterations=num_iterations,\n",
    "    checkpoint_interval_minutes=CHECKPOINT_INTERVAL_MINUTES,\n",
    "    resume=RESUME,\n",
    "    print_interval=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final metrics summary\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Metrics Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric_name, values in metrics.items():\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    print(f\"{metric_name}:\")\n",
    "    print(f\"  Mean: {mean:.4f} +/- {std:.4f}\")\n",
    "    print(f\"  Per-seed: {[f'{v:.4f}' for v in values]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Verify Checkpoints\n",
    "\n",
    "List saved checkpoints and print summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "print(\"Saved Checkpoints:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed_id in SEED_IDS:\n",
    "    seed_dir = os.path.join(CHECKPOINT_DIR, f\"seed_{seed_id}\")\n",
    "    checkpoints = sorted(glob.glob(os.path.join(seed_dir, \"step_*.pkl\")))\n",
    "    \n",
    "    print(f\"\\nSeed {seed_id}:\")\n",
    "    if checkpoints:\n",
    "        for ckpt in checkpoints[-3:]:  # Show last 3\n",
    "            size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "            print(f\"  {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Load latest and show step\n",
    "        latest = os.path.join(seed_dir, \"latest.pkl\")\n",
    "        if os.path.exists(latest):\n",
    "            with open(latest, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            print(f\"  Latest step: {data.get('step', 'unknown')}\")\n",
    "    else:\n",
    "        print(\"  No checkpoints found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Checkpoint verification complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary of all batches (run this to see overall progress)\nprint(\"Overall Progress Across All Conditions:\")\nprint(\"=\"*60)\n\nfor condition in [\"field_on\", \"field_off\"]:\n    print(f\"\\n{condition.upper()}:\")\n    print(\"-\"*40)\n    \n    condition_complete = 0\n    condition_expected = 30\n    \n    # 10 batches with 3 seeds each = 30 seeds\n    for batch in range(10):\n        batch_dir = os.path.join(CHECKPOINT_BASE, condition, f\"batch_{batch}\")\n        if os.path.exists(batch_dir):\n            batch_seeds = list(range(batch * 3, (batch + 1) * 3))\n            complete = 0\n            for seed_id in batch_seeds:\n                seed_dir = os.path.join(batch_dir, f\"seed_{seed_id}\")\n                latest = os.path.join(seed_dir, \"latest.pkl\")\n                if os.path.exists(latest):\n                    try:\n                        with open(latest, \"rb\") as f:\n                            data = pickle.load(f)\n                        step = data.get('step', 0)\n                        if step >= TOTAL_STEPS * 0.99:  # 99% complete\n                            complete += 1\n                            condition_complete += 1\n                    except:\n                        pass\n            print(f\"  Batch {batch} (seeds {batch*3}-{batch*3+2}): {complete}/3 complete\")\n        else:\n            print(f\"  Batch {batch} (seeds {batch*3}-{batch*3+2}): Not started\")\n    \n    print(f\"  â†’ {condition} total: {condition_complete}/{condition_expected} seeds\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Once both conditions have 30 seeds, run the report generator:\")\nprint(\"python scripts/generate_multi_seed_report.py \\\\\")\nprint(f\"    --checkpoint-dir {CHECKPOINT_BASE}/field_on \\\\\")\nprint(f\"    --compare-dir {CHECKPOINT_BASE}/field_off\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\n### Running the Full Experiment (60 seeds total)\n\n**Config**: PROVEN 64-agent config (grid=32, food=40, max_agents=64)\n\n**Phase 1: Field ON (30 seeds)**\n1. Set `FIELD_ENABLED = True` and `BATCH_NUMBER = 0`, run notebook\n2. Change `BATCH_NUMBER = 1`, run again\n3. Repeat for batches 2-9 (10 batches Ã— 3 seeds = 30 seeds)\n\n**Phase 2: Field OFF (30 seeds)**\n1. Set `FIELD_ENABLED = False` and `BATCH_NUMBER = 0`, run notebook\n2. Change `BATCH_NUMBER = 1`, run again\n3. Repeat for batches 2-9\n\n**Phase 3: Generate Report**\n```bash\npython scripts/generate_multi_seed_report.py \\\n    --checkpoint-dir /path/to/field_on \\\n    --compare-dir /path/to/field_off \\\n    --output-dir reports/multi_seed\n```\n\n### Directory Structure\n```\nemergence-lab/\nâ”œâ”€â”€ field_on/\nâ”‚   â”œâ”€â”€ batch_0/seed_0/, seed_1/, seed_2/\nâ”‚   â”œâ”€â”€ batch_1/seed_3/, seed_4/, seed_5/\nâ”‚   â””â”€â”€ ... (batches 2-9)\nâ””â”€â”€ field_off/\n    â”œâ”€â”€ batch_0/seed_0/, seed_1/, seed_2/\n    â””â”€â”€ ... (batches 2-9)\n```"
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "emergence_lab_parallel_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
