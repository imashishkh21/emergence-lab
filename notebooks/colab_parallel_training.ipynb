{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Emergence Lab - Parallel Multi-Seed Training on TPU\n\nThis notebook runs **3 seeds in parallel** on Google Colab TPU with the **PROVEN 64-AGENT CONFIG**.\n\n**Goal**: Run 30 seeds Field ON + 30 seeds Field OFF = 60 total runs for statistical significance.\n\n## Quick Start\n\n| Step | What to do |\n|------|------------|\n| **0** | **Run TEST MODE first** (cell after setup) |\n| 1 | If test passes, set `TEST_MODE = False`, then `BATCH_NUMBER = 0` |\n| 2 | Change `BATCH_NUMBER = 1`, run again |\n| ... | Continue batches 2-9 |\n| 11 | Set `FIELD_ENABLED = False`, `BATCH_NUMBER = 0` |\n| ... | Continue batches 1-9 |\n\n**Config**: 64 max agents, 32x32 grid, 40 food (proven UTOPIA config)\n\n## Setup Instructions\n\n1. Open this notebook in Google Colab\n2. Runtime > Change runtime type > **TPU v5e** (or v6e) + **High-RAM**\n3. Run setup cells (1-4)\n4. **Run TEST MODE cell first** - verify it passes before full training\n5. Then run full training cells"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup\n",
    "\n",
    "Mount Google Drive, clone the repo, and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory\n",
    "import os\n",
    "CHECKPOINT_BASE = '/content/drive/MyDrive/emergence-lab'\n",
    "os.makedirs(CHECKPOINT_BASE, exist_ok=True)\n",
    "print(f\"Checkpoint base: {CHECKPOINT_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repo if not already present\nREPO_DIR = '/content/emergence-lab'\n\n# âš ï¸ CHANGE THIS to your GitHub username\nGITHUB_USERNAME = \"imashishkh\"\n\nif not os.path.exists(REPO_DIR):\n    !git clone https://github.com/{GITHUB_USERNAME}/emergence-lab.git {REPO_DIR}\nelse:\n    print(f\"Repo already exists at {REPO_DIR}\")\n    # Pull latest changes\n    !cd {REPO_DIR} && git pull\n\n# Change to repo directory\nos.chdir(REPO_DIR)\nprint(f\"Working directory: {os.getcwd()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -e \".[dev]\" -q\n",
    "\n",
    "# Verify JAX sees TPU\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")\n",
    "print(f\"Device count: {jax.device_count()}\")\n",
    "\n",
    "# Check if TPU is available\n",
    "if 'tpu' in str(jax.devices()[0]).lower():\n",
    "    print(\"TPU detected!\")\n",
    "else:\n",
    "    print(\"WARNING: TPU not detected. Training will be slower on GPU/CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## âš ï¸ TEST MODE - Run This First!\n\nBefore running the full experiment, do a quick test to verify everything works.\nThis uses ~1% of compute and catches errors early.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# ðŸ§ª TEST RUN - Verify parallel training works before full experiment\n# =============================================================================\n# This runs 2 seeds for 100K steps (~1-2 minutes) to catch errors early.\n# If this succeeds, the full experiment should work.\n\nTEST_MODE = True  # Set to False to skip test and go straight to full training\n\nif TEST_MODE:\n    print(\"=\"*60)\n    print(\"ðŸ§ª TEST MODE: Running quick verification...\")\n    print(\"=\"*60)\n    \n    from src.configs import Config\n    from src.training.parallel_train import ParallelTrainer\n    import time\n    \n    # Minimal test config - MATCHES PROVEN 64-AGENT CONFIG\n    test_config = Config()\n    test_config.env.grid_size = 32        # Larger grid for 64 agents\n    test_config.env.num_agents = 16       # Starting population\n    test_config.env.num_food = 40         # More food for 64 agents\n    test_config.evolution.enabled = True\n    test_config.evolution.max_agents = 64 # PROVEN: 64 agents achieved UTOPIA\n    test_config.evolution.starting_energy = 200\n    test_config.evolution.food_energy = 100\n    test_config.evolution.reproduce_threshold = 120\n    test_config.evolution.reproduce_cost = 40  # PROVEN: 40 not 50\n    test_config.train.num_envs = 32\n    test_config.train.num_steps = 128\n    test_config.log.wandb = False\n    \n    # Test parameters: 2 seeds, 100K steps\n    TEST_STEPS = 100_000\n    TEST_SEEDS = 2\n    TEST_CHECKPOINT_DIR = f'{CHECKPOINT_BASE}/test_run'\n    \n    steps_per_iter = 32 * 128 * 64  # num_envs * num_steps * max_agents (64!)\n    test_iterations = max(1, TEST_STEPS // steps_per_iter)  # At least 1 iteration\n    \n    print(f\"Test config:\")\n    print(f\"  Seeds: {TEST_SEEDS}\")\n    print(f\"  Steps: {TEST_STEPS:,}\")\n    print(f\"  Iterations: {test_iterations}\")\n    print(f\"  Grid size: 32\")\n    print(f\"  Max agents: 64 (PROVEN CONFIG)\")\n    print(f\"  Checkpoint dir: {TEST_CHECKPOINT_DIR}\")\n    print()\n    \n    # Run test\n    try:\n        test_trainer = ParallelTrainer(\n            config=test_config,\n            num_seeds=TEST_SEEDS,\n            seed_ids=[100, 101],  # Use different IDs to avoid conflicts\n            checkpoint_dir=TEST_CHECKPOINT_DIR,\n            master_seed=9999,\n        )\n        \n        t0 = time.time()\n        test_metrics = test_trainer.train(\n            num_iterations=test_iterations,\n            checkpoint_interval_minutes=60,  # Won't trigger in short test\n            resume=False,\n            print_interval=5,\n        )\n        elapsed = time.time() - t0\n        \n        print()\n        print(\"=\"*60)\n        print(\"âœ… TEST PASSED!\")\n        print(\"=\"*60)\n        print(f\"Time: {elapsed:.1f}s\")\n        print(f\"Final reward: {test_metrics.get('mean_reward', ['N/A'])}\")\n        print()\n        print(\"The parallel training code works. You can now run the full experiment.\")\n        print(\"Set TEST_MODE = False in this cell and run the cells below.\")\n        print(\"=\"*60)\n        \n    except Exception as e:\n        print()\n        print(\"=\"*60)\n        print(\"âŒ TEST FAILED!\")\n        print(\"=\"*60)\n        print(f\"Error: {e}\")\n        print()\n        print(\"DO NOT proceed with full training until this is fixed.\")\n        print(\"Share the error message to debug.\")\n        print(\"=\"*60)\n        raise e\n\nelse:\n    print(\"TEST_MODE = False, skipping test.\")\n    print(\"Proceeding to full training configuration...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration\n",
    "\n",
    "Configure which seeds to run and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION - Edit these values as needed\n# =============================================================================\n\n# Which batch of seeds to run (0-9 for 30 total seeds with 3 seeds per batch)\n# Batch 0: seeds 0-2\n# Batch 1: seeds 3-5\n# Batch 2: seeds 6-8\n# Batch 3: seeds 9-11\n# Batch 4: seeds 12-14\n# Batch 5: seeds 15-17\n# Batch 6: seeds 18-20\n# Batch 7: seeds 21-23\n# Batch 8: seeds 24-26\n# Batch 9: seeds 27-29\nBATCH_NUMBER = 0  # Change this for each Colab session\n\n# Seeds per batch (3 for 64-agent config to avoid OOM)\n# With 64 max_agents, 3 seeds is safer than 5\nSEEDS_PER_BATCH = 3\n\n# Compute seed IDs for this batch\nSEED_IDS = list(range(BATCH_NUMBER * SEEDS_PER_BATCH, (BATCH_NUMBER + 1) * SEEDS_PER_BATCH))\n\n# Training parameters\nTOTAL_STEPS = 10_000_000  # Total environment steps per seed\nNUM_ENVS = 32  # Parallel environments per seed\nNUM_STEPS = 128  # Steps per rollout\n\n# Field ablation setting\n# Set to True for normal training, False for ablation (no field)\nFIELD_ENABLED = True\n\n# Checkpoint directory - SEPARATE for field_on vs field_off\nCONDITION_NAME = \"field_on\" if FIELD_ENABLED else \"field_off\"\nCHECKPOINT_DIR = f'{CHECKPOINT_BASE}/{CONDITION_NAME}/batch_{BATCH_NUMBER}'\n\n# Checkpoint interval in minutes\nCHECKPOINT_INTERVAL_MINUTES = 30\n\n# Resume from existing checkpoints?\nRESUME = True\n\n# =============================================================================\n# Print configuration summary\n# =============================================================================\nprint(\"=\"*60)\nprint(\"Configuration Summary\")\nprint(\"=\"*60)\nprint(f\"Condition: {CONDITION_NAME}\")\nprint(f\"Batch number: {BATCH_NUMBER}\")\nprint(f\"Seed IDs: {SEED_IDS}\")\nprint(f\"Seeds per batch: {SEEDS_PER_BATCH} (3 for 64-agent safety)\")\nprint(f\"Total steps per seed: {TOTAL_STEPS:,}\")\nprint(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\nprint(f\"Checkpoint interval: {CHECKPOINT_INTERVAL_MINUTES} minutes\")\nprint(f\"Field enabled: {FIELD_ENABLED}\")\nprint(f\"Resume from checkpoints: {RESUME}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build configuration\nfrom src.configs import Config, EnvConfig, EvolutionConfig, FieldConfig\n\n# Start with default config\nconfig = Config()\n\n# =============================================================================\n# PROVEN 64-AGENT CONFIG (from seeds 42-45 that achieved UTOPIA)\n# This exact config produced:\n#   - Seed 44: UTOPIA (64 agents, reward 5.62)\n#   - Seed 43: THRIVING (62 agents, reward 5.36)\n#   - Emergence events detected in 3/4 seeds\n# =============================================================================\nconfig.env.grid_size = 32             # Larger grid for 64 agents (default 20)\nconfig.env.num_agents = 16            # Starting population (default 8)\nconfig.env.num_food = 40              # More food for 64 agents (default 10)\n\nconfig.evolution.enabled = True\nconfig.evolution.max_agents = 64      # PROVEN: 64 achieved UTOPIA\nconfig.evolution.starting_energy = 200  # Survival-friendly\nconfig.evolution.food_energy = 100    # High energy per food\nconfig.evolution.energy_per_step = 1  # Energy drain per step\nconfig.evolution.reproduce_threshold = 120  # Easier to reproduce\nconfig.evolution.reproduce_cost = 40  # PROVEN: 40 not 50!\nconfig.evolution.mutation_std = 0.01  # Standard mutation rate\n\n# Training parameters\nconfig.train.total_steps = TOTAL_STEPS\nconfig.train.num_envs = NUM_ENVS\nconfig.train.num_steps = NUM_STEPS\nconfig.train.seed = 42  # Master seed (individual seeds are derived)\n\n# Field ablation (if disabled, zero out the field)\nif not FIELD_ENABLED:\n    # Zero out field by setting decay to 1.0 (field becomes zero before observation)\n    config.field.decay_rate = 1.0\n    config.field.diffusion_rate = 0.0\n    config.field.write_strength = 0.0\n\n# Logging (disable W&B for parallel training)\nconfig.log.wandb = False\nconfig.log.save_interval = 0  # We handle checkpointing ourselves\n\nprint(\"=\"*60)\nprint(\"PROVEN 64-AGENT CONFIG LOADED\")\nprint(\"=\"*60)\nprint(f\"  Grid size: {config.env.grid_size}\")\nprint(f\"  Starting agents: {config.env.num_agents}\")\nprint(f\"  Num food: {config.env.num_food}\")\nprint(f\"  Max agents: {config.evolution.max_agents}\")\nprint(f\"  Starting energy: {config.evolution.starting_energy}\")\nprint(f\"  Food energy: {config.evolution.food_energy}\")\nprint(f\"  Reproduce threshold: {config.evolution.reproduce_threshold}\")\nprint(f\"  Reproduce cost: {config.evolution.reproduce_cost}\")\nprint(f\"  Field channels: {config.field.num_channels}\")\nprint(f\"  Field enabled: {FIELD_ENABLED}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Training\n",
    "\n",
    "Run parallel training with automatic checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.parallel_train import ParallelTrainer\n",
    "\n",
    "# Calculate number of iterations\n",
    "steps_per_iter = NUM_ENVS * NUM_STEPS * config.evolution.max_agents\n",
    "num_iterations = TOTAL_STEPS // steps_per_iter\n",
    "\n",
    "print(f\"Steps per iteration: {steps_per_iter:,}\")\n",
    "print(f\"Number of iterations: {num_iterations:,}\")\n",
    "print()\n",
    "\n",
    "# Create trainer\n",
    "trainer = ParallelTrainer(\n",
    "    config=config,\n",
    "    num_seeds=SEEDS_PER_BATCH,\n",
    "    seed_ids=SEED_IDS,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    master_seed=42 + BATCH_NUMBER * 1000,  # Different master seed per batch\n",
    ")\n",
    "\n",
    "# Run training\n",
    "metrics = trainer.train(\n",
    "    num_iterations=num_iterations,\n",
    "    checkpoint_interval_minutes=CHECKPOINT_INTERVAL_MINUTES,\n",
    "    resume=RESUME,\n",
    "    print_interval=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final metrics summary\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Metrics Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric_name, values in metrics.items():\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    print(f\"{metric_name}:\")\n",
    "    print(f\"  Mean: {mean:.4f} +/- {std:.4f}\")\n",
    "    print(f\"  Per-seed: {[f'{v:.4f}' for v in values]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Verify Checkpoints\n",
    "\n",
    "List saved checkpoints and print summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "print(\"Saved Checkpoints:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed_id in SEED_IDS:\n",
    "    seed_dir = os.path.join(CHECKPOINT_DIR, f\"seed_{seed_id}\")\n",
    "    checkpoints = sorted(glob.glob(os.path.join(seed_dir, \"step_*.pkl\")))\n",
    "    \n",
    "    print(f\"\\nSeed {seed_id}:\")\n",
    "    if checkpoints:\n",
    "        for ckpt in checkpoints[-3:]:  # Show last 3\n",
    "            size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "            print(f\"  {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Load latest and show step\n",
    "        latest = os.path.join(seed_dir, \"latest.pkl\")\n",
    "        if os.path.exists(latest):\n",
    "            with open(latest, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            print(f\"  Latest step: {data.get('step', 'unknown')}\")\n",
    "    else:\n",
    "        print(\"  No checkpoints found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Checkpoint verification complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary of all batches (run this to see overall progress)\nprint(\"Overall Progress Across All Conditions:\")\nprint(\"=\"*60)\n\nfor condition in [\"field_on\", \"field_off\"]:\n    print(f\"\\n{condition.upper()}:\")\n    print(\"-\"*40)\n    \n    condition_complete = 0\n    condition_expected = 30\n    \n    # 10 batches with 3 seeds each = 30 seeds\n    for batch in range(10):\n        batch_dir = os.path.join(CHECKPOINT_BASE, condition, f\"batch_{batch}\")\n        if os.path.exists(batch_dir):\n            batch_seeds = list(range(batch * 3, (batch + 1) * 3))\n            complete = 0\n            for seed_id in batch_seeds:\n                seed_dir = os.path.join(batch_dir, f\"seed_{seed_id}\")\n                latest = os.path.join(seed_dir, \"latest.pkl\")\n                if os.path.exists(latest):\n                    try:\n                        with open(latest, \"rb\") as f:\n                            data = pickle.load(f)\n                        step = data.get('step', 0)\n                        if step >= TOTAL_STEPS * 0.99:  # 99% complete\n                            complete += 1\n                            condition_complete += 1\n                    except:\n                        pass\n            print(f\"  Batch {batch} (seeds {batch*3}-{batch*3+2}): {complete}/3 complete\")\n        else:\n            print(f\"  Batch {batch} (seeds {batch*3}-{batch*3+2}): Not started\")\n    \n    print(f\"  â†’ {condition} total: {condition_complete}/{condition_expected} seeds\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Once both conditions have 30 seeds, run the report generator:\")\nprint(\"python scripts/generate_multi_seed_report.py \\\\\")\nprint(f\"    --checkpoint-dir {CHECKPOINT_BASE}/field_on \\\\\")\nprint(f\"    --compare-dir {CHECKPOINT_BASE}/field_off\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\n### Running the Full Experiment (60 seeds total)\n\n**Config**: PROVEN 64-agent config (grid=32, food=40, max_agents=64)\n\n**Phase 1: Field ON (30 seeds)**\n1. Set `FIELD_ENABLED = True` and `BATCH_NUMBER = 0`, run notebook\n2. Change `BATCH_NUMBER = 1`, run again\n3. Repeat for batches 2-9 (10 batches Ã— 3 seeds = 30 seeds)\n\n**Phase 2: Field OFF (30 seeds)**\n1. Set `FIELD_ENABLED = False` and `BATCH_NUMBER = 0`, run notebook\n2. Change `BATCH_NUMBER = 1`, run again\n3. Repeat for batches 2-9\n\n**Phase 3: Generate Report**\n```bash\npython scripts/generate_multi_seed_report.py \\\n    --checkpoint-dir /path/to/field_on \\\n    --compare-dir /path/to/field_off \\\n    --output-dir reports/multi_seed\n```\n\n### Directory Structure\n```\nemergence-lab/\nâ”œâ”€â”€ field_on/\nâ”‚   â”œâ”€â”€ batch_0/seed_0/, seed_1/, seed_2/\nâ”‚   â”œâ”€â”€ batch_1/seed_3/, seed_4/, seed_5/\nâ”‚   â””â”€â”€ ... (batches 2-9)\nâ””â”€â”€ field_off/\n    â”œâ”€â”€ batch_0/seed_0/, seed_1/, seed_2/\n    â””â”€â”€ ... (batches 2-9)\n```"
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "emergence_lab_parallel_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}