{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Food Coordination Training \u2014 Field ON vs Field OFF\n",
    "\n",
    "Train 30 seeds x 2 conditions with hidden food enabled.\n",
    "Hidden food requires K=3 agents within distance 3 to reveal \u2014 the field should enable this.\n",
    "\n",
    "## Config\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Grid | 32x32 |\n",
    "| Starting agents | 16 |\n",
    "| Max agents | 64 |\n",
    "| Regular food | 40 |\n",
    "| Hidden food items | 3 |\n",
    "| Required agents to reveal | 3 |\n",
    "| Reveal distance | 3 (Chebyshev) |\n",
    "| Hidden food value | 5x (500 energy) |\n",
    "| Steps per seed | 10M |\n",
    "| Seeds per condition | 30 (10 batches x 3) |\n",
    "\n",
    "## Runtime\n",
    "- TPU v6e + High-RAM\n",
    "- Expected: ~8-12 hours per condition on TPU v6e\n",
    "- Run all cells (Ctrl+F9), come back when done\n",
    "- Resume-safe: re-run after disconnect and it picks up from checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Mount Google Drive, clone repo, install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "CHECKPOINT_BASE = '/content/drive/MyDrive/emergence-lab'\n",
    "os.makedirs(CHECKPOINT_BASE, exist_ok=True)\n",
    "\n",
    "REPO_DIR = '/content/emergence-lab'\n",
    "GITHUB_USERNAME = \"imashishkh21\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/{GITHUB_USERNAME}/emergence-lab.git {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "!pip install -e \".[dev,phase5]\" -q\n",
    "\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")\n",
    "print(f\"Device count: {jax.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEST RUN - Verify hidden food mechanics + parallel training before full run\n",
    "# =============================================================================\n",
    "import copy\n",
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from src.configs import Config\n",
    "from src.training.parallel_train import ParallelTrainer\n",
    "from src.environment.env import reset, step\n",
    "from src.environment.obs import get_observations\n",
    "\n",
    "# --- Test 1: Hidden food env mechanics ---\n",
    "print(\"[1/3] Testing hidden food environment mechanics...\")\n",
    "test_cfg = Config()\n",
    "test_cfg.env.grid_size = 32\n",
    "test_cfg.env.num_agents = 16\n",
    "test_cfg.env.num_food = 40\n",
    "test_cfg.evolution.enabled = True\n",
    "test_cfg.evolution.max_agents = 64\n",
    "test_cfg.evolution.starting_energy = 200\n",
    "test_cfg.evolution.food_energy = 100\n",
    "test_cfg.evolution.reproduce_threshold = 120\n",
    "test_cfg.evolution.reproduce_cost = 40\n",
    "\n",
    "# Enable hidden food\n",
    "test_cfg.env.hidden_food.enabled = True\n",
    "test_cfg.env.hidden_food.num_hidden = 3\n",
    "test_cfg.env.hidden_food.required_agents = 3\n",
    "test_cfg.env.hidden_food.reveal_distance = 3\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "state = reset(key, test_cfg)\n",
    "assert state.hidden_food_positions is not None, \"hidden_food_positions is None!\"\n",
    "assert state.hidden_food_positions.shape == (3, 2), f\"Wrong shape: {state.hidden_food_positions.shape}\"\n",
    "assert state.hidden_food_revealed is not None\n",
    "\n",
    "# Do one step\n",
    "actions = jnp.zeros(64, dtype=jnp.int32)  # all stay\n",
    "state2, rewards, done, info = step(state, actions, test_cfg)\n",
    "assert 'hidden_food_collected_this_step' in info\n",
    "assert 'food_collected_this_step' in info\n",
    "assert 'births_this_step' in info\n",
    "print(\"   PASS: Hidden food env works. Shapes verified.\")\n",
    "\n",
    "# --- Test 2: Field ON parallel training ---\n",
    "print(\"\\n[2/3] Testing Field ON parallel training (2 seeds, 100K steps)...\")\n",
    "field_on_cfg = copy.deepcopy(test_cfg)\n",
    "field_on_cfg.train.num_envs = 32\n",
    "field_on_cfg.train.num_steps = 128\n",
    "field_on_cfg.log.wandb = False\n",
    "# Field ON defaults: diffusion=0.1, decay=0.05, write=1.0\n",
    "\n",
    "steps_per_iter = 32 * 128 * 64\n",
    "test_iters = max(1, 100_000 // steps_per_iter)\n",
    "\n",
    "trainer_on = ParallelTrainer(\n",
    "    config=field_on_cfg, num_seeds=2, seed_ids=[100, 101],\n",
    "    checkpoint_dir=f'{CHECKPOINT_BASE}/test_hidden_food_on', master_seed=9999,\n",
    ")\n",
    "t0 = time.time()\n",
    "metrics_on = trainer_on.train(num_iterations=test_iters, checkpoint_interval_minutes=60, resume=False)\n",
    "print(f\"   PASS: Field ON test done in {time.time()-t0:.1f}s, reward={metrics_on.get('mean_reward', 'N/A')}\")\n",
    "\n",
    "# --- Test 3: Field OFF parallel training ---\n",
    "print(\"\\n[3/3] Testing Field OFF parallel training (2 seeds, 100K steps)...\")\n",
    "field_off_cfg = copy.deepcopy(test_cfg)\n",
    "field_off_cfg.train.num_envs = 32\n",
    "field_off_cfg.train.num_steps = 128\n",
    "field_off_cfg.log.wandb = False\n",
    "field_off_cfg.field.diffusion_rate = 0.0\n",
    "field_off_cfg.field.decay_rate = 1.0\n",
    "field_off_cfg.field.write_strength = 0.0\n",
    "\n",
    "trainer_off = ParallelTrainer(\n",
    "    config=field_off_cfg, num_seeds=2, seed_ids=[200, 201],\n",
    "    checkpoint_dir=f'{CHECKPOINT_BASE}/test_hidden_food_off', master_seed=8888,\n",
    ")\n",
    "t0 = time.time()\n",
    "metrics_off = trainer_off.train(num_iterations=test_iters, checkpoint_interval_minutes=60, resume=False)\n",
    "print(f\"   PASS: Field OFF test done in {time.time()-t0:.1f}s, reward={metrics_off.get('mean_reward', 'N/A')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL 3 TESTS PASSED! Proceed to full training.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Build Field ON and Field OFF configs with hidden food enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from src.configs import Config\n",
    "from src.training.parallel_train import ParallelTrainer\n",
    "\n",
    "TOTAL_STEPS = 10_000_000\n",
    "NUM_ENVS = 32\n",
    "NUM_STEPS = 128\n",
    "SEEDS_PER_BATCH = 3\n",
    "TOTAL_BATCHES = 10  # 10 batches x 3 seeds = 30 seeds per condition\n",
    "CHECKPOINT_INTERVAL_MINUTES = 30\n",
    "RESUME = True\n",
    "\n",
    "CHECKPOINT_DIRS = {\n",
    "    'field_on': f'{CHECKPOINT_BASE}/hidden_food_field_on',\n",
    "    'field_off': f'{CHECKPOINT_BASE}/hidden_food_field_off',\n",
    "}\n",
    "\n",
    "\n",
    "def build_config(field_enabled: bool) -> Config:\n",
    "    \"\"\"Build PROVEN 64-agent config with hidden food.\"\"\"\n",
    "    config = Config()\n",
    "\n",
    "    # PROVEN 64-AGENT CONFIG\n",
    "    config.env.grid_size = 32\n",
    "    config.env.num_agents = 16\n",
    "    config.env.num_food = 40\n",
    "    config.evolution.enabled = True\n",
    "    config.evolution.max_agents = 64\n",
    "    config.evolution.starting_energy = 200\n",
    "    config.evolution.food_energy = 100\n",
    "    config.evolution.energy_per_step = 1\n",
    "    config.evolution.reproduce_threshold = 120\n",
    "    config.evolution.reproduce_cost = 40\n",
    "    config.evolution.mutation_std = 0.01\n",
    "\n",
    "    # HIDDEN FOOD - the coordination task\n",
    "    config.env.hidden_food.enabled = True\n",
    "    config.env.hidden_food.num_hidden = 3\n",
    "    config.env.hidden_food.required_agents = 3\n",
    "    config.env.hidden_food.reveal_distance = 3\n",
    "    # reveal_duration=10 and hidden_food_value_multiplier=5.0 are defaults\n",
    "\n",
    "    # Training\n",
    "    config.train.total_steps = TOTAL_STEPS\n",
    "    config.train.num_envs = NUM_ENVS\n",
    "    config.train.num_steps = NUM_STEPS\n",
    "    config.train.seed = 42\n",
    "    config.log.wandb = False\n",
    "    config.log.save_interval = 0\n",
    "\n",
    "    if field_enabled:\n",
    "        # Field ON: use defaults (diffusion=0.1, decay=0.05, write=1.0)\n",
    "        pass\n",
    "    else:\n",
    "        # Field OFF: zero out field\n",
    "        config.field.diffusion_rate = 0.0\n",
    "        config.field.decay_rate = 1.0\n",
    "        config.field.write_strength = 0.0\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "# Print config summary\n",
    "for cond, enabled in [('Field ON', True), ('Field OFF', False)]:\n",
    "    cfg = build_config(enabled)\n",
    "    print(f\"{cond}: diffusion={cfg.field.diffusion_rate}, decay={cfg.field.decay_rate}, \"\n",
    "          f\"write={cfg.field.write_strength}, hidden_food={cfg.env.hidden_food.enabled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autonomous Training \u2014 Field ON + Field OFF\n",
    "\n",
    "Runs all 10 batches for Field ON, then all 10 batches for Field OFF.\n",
    "Total: 60 seeds (30 per condition) at 10M steps each.\n",
    "\n",
    "Expected runtime: ~8-12 hours per condition on TPU v6e.\n",
    "Resume-safe: re-run and it picks up from latest checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run both conditions sequentially\n",
    "for condition_name, field_enabled in [('field_on', True), ('field_off', False)]:\n",
    "    config = build_config(field_enabled)\n",
    "    checkpoint_dir_base = CHECKPOINT_DIRS[condition_name]\n",
    "    os.makedirs(checkpoint_dir_base, exist_ok=True)\n",
    "\n",
    "    steps_per_iter = NUM_ENVS * NUM_STEPS * config.evolution.max_agents\n",
    "    num_iterations = TOTAL_STEPS // steps_per_iter\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"CONDITION: {condition_name.upper()} (field_enabled={field_enabled})\")\n",
    "    print(f\"Hidden food: enabled={config.env.hidden_food.enabled}\")\n",
    "    print(f\"Batches: {TOTAL_BATCHES}, Seeds/batch: {SEEDS_PER_BATCH}\")\n",
    "    print(f\"Iterations: {num_iterations}, Steps/iter: {steps_per_iter:,}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    all_results = []\n",
    "    cond_start = time.time()\n",
    "\n",
    "    for batch_number in range(TOTAL_BATCHES):\n",
    "        seed_ids = list(range(batch_number * SEEDS_PER_BATCH, (batch_number + 1) * SEEDS_PER_BATCH))\n",
    "        checkpoint_dir = f'{checkpoint_dir_base}/batch_{batch_number}'\n",
    "\n",
    "        print(f\"\\n--- Batch {batch_number+1}/{TOTAL_BATCHES} | Seeds: {seed_ids} ---\")\n",
    "\n",
    "        try:\n",
    "            trainer = ParallelTrainer(\n",
    "                config=config, num_seeds=SEEDS_PER_BATCH, seed_ids=seed_ids,\n",
    "                checkpoint_dir=checkpoint_dir, master_seed=42 + batch_number * 1000,\n",
    "            )\n",
    "            metrics = trainer.train(\n",
    "                num_iterations=num_iterations,\n",
    "                checkpoint_interval_minutes=CHECKPOINT_INTERVAL_MINUTES,\n",
    "                resume=RESUME, print_interval=100,\n",
    "            )\n",
    "            all_results.append({\n",
    "                'batch': batch_number, 'seed_ids': seed_ids,\n",
    "                'metrics': metrics, 'success': True,\n",
    "            })\n",
    "            if 'mean_reward' in metrics:\n",
    "                print(f\"  Rewards: {metrics['mean_reward']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            all_results.append({\n",
    "                'batch': batch_number, 'seed_ids': seed_ids,\n",
    "                'error': str(e), 'success': False,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Progress estimate\n",
    "        batches_done = batch_number + 1\n",
    "        total_elapsed = time.time() - cond_start\n",
    "        avg_per_batch = total_elapsed / batches_done\n",
    "        remaining = avg_per_batch * (TOTAL_BATCHES - batches_done)\n",
    "        eta = datetime.now() + timedelta(seconds=remaining)\n",
    "        print(f\"  Progress: {batches_done}/{TOTAL_BATCHES} | \"\n",
    "              f\"Elapsed: {total_elapsed/3600:.1f}h | ETA: {eta.strftime('%H:%M')}\")\n",
    "\n",
    "    # Save training summary for this condition\n",
    "    cond_time = time.time() - cond_start\n",
    "    summary_path = f'{checkpoint_dir_base}/training_summary.pkl'\n",
    "    with open(summary_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'all_results': all_results,\n",
    "            'total_time_seconds': cond_time,\n",
    "            'condition': condition_name,\n",
    "            'hidden_food_enabled': True,\n",
    "            'total_steps': TOTAL_STEPS,\n",
    "            'config': {\n",
    "                'grid_size': config.env.grid_size,\n",
    "                'num_food': config.env.num_food,\n",
    "                'max_agents': config.evolution.max_agents,\n",
    "                'reproduce_threshold': config.evolution.reproduce_threshold,\n",
    "                'reproduce_cost': config.evolution.reproduce_cost,\n",
    "                'hidden_food_num_hidden': config.env.hidden_food.num_hidden,\n",
    "                'hidden_food_required_agents': config.env.hidden_food.required_agents,\n",
    "                'hidden_food_reveal_distance': config.env.hidden_food.reveal_distance,\n",
    "                'hidden_food_value_multiplier': config.env.hidden_food.hidden_food_value_multiplier,\n",
    "            },\n",
    "        }, f)\n",
    "    print(f\"\\n{condition_name} complete! Time: {cond_time/3600:.1f}h\")\n",
    "    print(f\"Summary saved: {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "Scan all checkpoints for both conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob_mod\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CHECKPOINT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for condition_name in ['field_on', 'field_off']:\n",
    "    checkpoint_dir_base = CHECKPOINT_DIRS[condition_name]\n",
    "    print(f\"\\n{condition_name.upper()}:\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    total_complete = 0\n",
    "    total_partial = 0\n",
    "    total_missing = 0\n",
    "    total_error = 0\n",
    "\n",
    "    for batch_idx in range(TOTAL_BATCHES):\n",
    "        batch_dir = os.path.join(checkpoint_dir_base, f'batch_{batch_idx}')\n",
    "        if not os.path.exists(batch_dir):\n",
    "            seed_ids = list(range(batch_idx * SEEDS_PER_BATCH, (batch_idx + 1) * SEEDS_PER_BATCH))\n",
    "            print(f\"  Batch {batch_idx} (seeds {seed_ids}): NOT STARTED\")\n",
    "            total_missing += SEEDS_PER_BATCH\n",
    "            continue\n",
    "\n",
    "        batch_status = []\n",
    "        for seed_dir in sorted(os.listdir(batch_dir)):\n",
    "            seed_path = os.path.join(batch_dir, seed_dir)\n",
    "            if not os.path.isdir(seed_path):\n",
    "                continue\n",
    "            pkl_files = glob_mod.glob(os.path.join(seed_path, 'step_*.pkl'))\n",
    "            if pkl_files:\n",
    "                latest = sorted(pkl_files)[-1]\n",
    "                size_mb = os.path.getsize(latest) / (1024 * 1024)\n",
    "                batch_status.append(f\"{seed_dir}: {os.path.basename(latest)} ({size_mb:.1f}MB)\")\n",
    "                total_complete += 1\n",
    "            else:\n",
    "                batch_status.append(f\"{seed_dir}: no checkpoints\")\n",
    "                total_partial += 1\n",
    "\n",
    "        seed_ids = list(range(batch_idx * SEEDS_PER_BATCH, (batch_idx + 1) * SEEDS_PER_BATCH))\n",
    "        print(f\"  Batch {batch_idx} (seeds {seed_ids}): {len(batch_status)} seeds\")\n",
    "        for s in batch_status:\n",
    "            print(f\"    {s}\")\n",
    "\n",
    "    # Load training summary if available\n",
    "    summary_path = os.path.join(checkpoint_dir_base, 'training_summary.pkl')\n",
    "    if os.path.exists(summary_path):\n",
    "        with open(summary_path, 'rb') as f:\n",
    "            summary = pickle.load(f)\n",
    "        n_success = sum(1 for r in summary['all_results'] if r.get('success', False))\n",
    "        n_fail = sum(1 for r in summary['all_results'] if not r.get('success', True))\n",
    "        print(f\"\\n  Summary: {n_success} successful batches, {n_fail} failed\")\n",
    "        if 'total_time_seconds' in summary:\n",
    "            print(f\"  Total time: {summary['total_time_seconds']/3600:.1f}h\")\n",
    "\n",
    "    print(f\"\\n  Complete: {total_complete} | Partial: {total_partial} | Missing: {total_missing}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Next: Run the analysis notebook (colab_hidden_food_analysis.ipynb)\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}