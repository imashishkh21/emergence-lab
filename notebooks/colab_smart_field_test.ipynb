{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Field Test: Does State-Dependent Writing Improve Collective Intelligence?\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "| Prediction | Mechanism |\n",
    "|------------|----------|\n",
    "| Smart field > Presence field > No field | State-dependent writes encode richer information (energy, food found, reproduction readiness) into each channel |\n",
    "| Smart field agents coordinate better for hidden food | Channels carry semantic meaning (ch0=energy, ch1=food, ch2=hidden food, ch3=reproduction), enabling targeted coordination |\n",
    "| Presence field still beats no field | Even uniform presence marks carry spatial memory of agent activity |\n",
    "| The gap widens under harsh conditions | Richer field information becomes essential when food is scarce |\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "| Condition | Field | write_mode | Seeds | Steps |\n",
    "|-----------|-------|------------|-------|-------|\n",
    "| **Field OFF** | diffusion=0, decay=1, write=0 | presence | 15 | 10M |\n",
    "| **Field ON (presence)** | default (diffusion=0.1, decay=0.05, write=1.0) | presence | 15 | 10M |\n",
    "| **Field ON (smart)** | default (diffusion=0.1, decay=0.05, write=1.0) | state_dependent | 15 | 10M |\n",
    "\n",
    "## Harsh Environment Config\n",
    "\n",
    "| Parameter | Value | Why |\n",
    "|-----------|-------|-----|\n",
    "| grid_size | 40 | Larger arena = harder to find food |\n",
    "| num_food | 10 | **SCARCE** (vs 40 in standard config) |\n",
    "| food_energy | 60 | **REDUCED** (vs 100 standard) |\n",
    "| num_hidden | 8 | Abundant hidden food \\u2014 the coordination prize |\n",
    "| required_agents | 5 | Hard coordination requirement |\n",
    "| reveal_distance | 3 | Chebyshev distance for reveal |\n",
    "| hidden_food_value_multiplier | 10.0 | Each hidden food worth 600 energy (10x regular) |\n",
    "| max_agents | 64 | Population cap |\n",
    "| starting_energy | 200 | Starting energy per agent |\n",
    "| reproduce_threshold | 120 | Energy needed to reproduce |\n",
    "| reproduce_cost | 40 | Energy cost of reproduction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "if not os.path.exists('/content/emergence-lab'):\n",
    "    !git clone https://github.com/imashishkh21/emergence-lab.git /content/emergence-lab\n",
    "%cd /content/emergence-lab\n",
    "!git pull origin main\n",
    "\n",
    "!pip install -e \".[dev]\" -q\n",
    "!pip install rliable -q\n",
    "\n",
    "# Verify write_mode support\n",
    "from src.configs import FieldConfig\n",
    "assert hasattr(FieldConfig, 'write_mode'), \"FieldConfig missing write_mode! Pull latest main.\"\n",
    "print(f\"FieldConfig.write_mode default: {FieldConfig().write_mode}\")\n",
    "\n",
    "import jax\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 \\u2014 Quick Validation\n",
    "\n",
    "Before committing to 45 full training runs, verify:\n",
    "1. Populations survive the harsh environment (at least one condition has mean pop > 10)\n",
    "2. Check if hidden food is being revealed at all (may take longer than 2M steps)\n",
    "\n",
    "**Setup**: 3 seeds per condition (9 runs total), ~2M steps (~8 iterations of 262K steps each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, gc\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from src.configs import Config, TrainingMode\n",
    "from src.training.parallel_train import ParallelTrainer\n",
    "from src.agents.network import ActorCritic\n",
    "from src.agents.policy import get_deterministic_actions\n",
    "from src.environment.env import reset, step\n",
    "from src.environment.obs import get_observations\n",
    "\n",
    "NUM_ENVS = 32\n",
    "NUM_STEPS = 128\n",
    "MAX_AGENTS = 64\n",
    "STEPS_PER_ITER = NUM_ENVS * NUM_STEPS * MAX_AGENTS  # 262,144\n",
    "VALIDATION_ITERS = 8  # ~2M steps\n",
    "\n",
    "\n",
    "def build_config(mode: str) -> Config:\n",
    "    \"\"\"Build harsh environment config for smart field experiment.\n",
    "\n",
    "    Args:\n",
    "        mode: One of 'field_off', 'field_on_presence', 'field_on_smart'\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    # Large grid, scarce resources\n",
    "    config.env.grid_size = 40\n",
    "    config.env.num_agents = 16\n",
    "    config.env.num_food = 10              # SCARCE\n",
    "    config.env.max_steps = 500\n",
    "    config.evolution.enabled = True\n",
    "    config.evolution.max_agents = 64\n",
    "    config.evolution.starting_energy = 200\n",
    "    config.evolution.food_energy = 60     # REDUCED\n",
    "    config.evolution.energy_per_step = 1\n",
    "    config.evolution.reproduce_threshold = 120\n",
    "    config.evolution.reproduce_cost = 40\n",
    "    config.evolution.mutation_std = 0.01\n",
    "    # Hidden food\n",
    "    config.env.hidden_food.enabled = True\n",
    "    config.env.hidden_food.num_hidden = 8\n",
    "    config.env.hidden_food.required_agents = 5\n",
    "    config.env.hidden_food.reveal_distance = 3\n",
    "    config.env.hidden_food.hidden_food_value_multiplier = 10.0\n",
    "    # Training\n",
    "    config.train.training_mode = TrainingMode.GRADIENT\n",
    "    config.train.num_envs = NUM_ENVS\n",
    "    config.train.num_steps = NUM_STEPS\n",
    "    config.train.seed = 42\n",
    "    config.log.wandb = False\n",
    "    config.log.save_interval = 0\n",
    "\n",
    "    # Field configuration per mode\n",
    "    if mode == 'field_off':\n",
    "        config.field.diffusion_rate = 0.0\n",
    "        config.field.decay_rate = 1.0\n",
    "        config.field.write_strength = 0.0\n",
    "        config.field.write_mode = 'presence'\n",
    "    elif mode == 'field_on_presence':\n",
    "        # Default field params, presence writing\n",
    "        config.field.write_mode = 'presence'\n",
    "    elif mode == 'field_on_smart':\n",
    "        # Default field params, state-dependent writing\n",
    "        config.field.write_mode = 'state_dependent'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}. Use 'field_off', 'field_on_presence', or 'field_on_smart'\")\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def run_hidden_food_eval(network, params, config, key, num_episodes=1):\n",
    "    \"\"\"Run eval episodes tracking hidden food metrics.\"\"\"\n",
    "    all_results = []\n",
    "    for ep in range(num_episodes):\n",
    "        key, ep_key = jax.random.split(key)\n",
    "        state = reset(ep_key, config)\n",
    "        ep_reward = 0.0\n",
    "        ep_regular_food = 0.0\n",
    "        ep_hf_revealed = 0\n",
    "        ep_hf_collected = 0.0\n",
    "        for t in range(config.env.max_steps):\n",
    "            obs = get_observations(state, config)\n",
    "            obs_batched = obs[None, :, :]  # (1, max_agents, obs_dim)\n",
    "            actions = get_deterministic_actions(network, params, obs_batched)\n",
    "            actions = actions[0]  # (max_agents,)\n",
    "            pre_revealed = state.hidden_food_revealed\n",
    "            state, rewards, done, info = step(state, actions, config)\n",
    "            ep_reward += float(jnp.sum(rewards))\n",
    "            ep_regular_food += float(info['food_collected_this_step'])\n",
    "            ep_hf_collected += float(info['hidden_food_collected_this_step'])\n",
    "            if pre_revealed is not None and state.hidden_food_revealed is not None:\n",
    "                newly_revealed = (~pre_revealed) & state.hidden_food_revealed\n",
    "                ep_hf_revealed += int(jnp.sum(newly_revealed))\n",
    "            if bool(done):\n",
    "                break\n",
    "        food_energy = config.evolution.food_energy\n",
    "        hf_multiplier = config.env.hidden_food.hidden_food_value_multiplier\n",
    "        all_results.append({\n",
    "            'total_reward': ep_reward,\n",
    "            'regular_food_collected': ep_regular_food,\n",
    "            'hidden_food_revealed': ep_hf_revealed,\n",
    "            'hidden_food_collected': ep_hf_collected,\n",
    "            'regular_food_energy': ep_regular_food * food_energy,\n",
    "            'hidden_food_energy': ep_hf_collected * food_energy * hf_multiplier,\n",
    "            'final_population': int(jnp.sum(state.agent_alive.astype(jnp.int32))),\n",
    "        })\n",
    "    agg = {k: np.mean([r[k] for r in all_results]) for k in all_results[0]}\n",
    "    agg['per_episode'] = all_results\n",
    "    return agg\n",
    "\n",
    "\n",
    "# --- Validation training ---\n",
    "CONDITIONS = [\n",
    "    ('field_off', [200, 201, 202]),\n",
    "    ('field_on_presence', [203, 204, 205]),\n",
    "    ('field_on_smart', [206, 207, 208]),\n",
    "]\n",
    "\n",
    "validation_results = {}\n",
    "for cond_name, seed_ids in CONDITIONS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"VALIDATION: {cond_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    config = build_config(cond_name)\n",
    "    trainer = ParallelTrainer(\n",
    "        config=config, num_seeds=3, seed_ids=seed_ids,\n",
    "        checkpoint_dir=f'/tmp/validation_{cond_name}', master_seed=9999,\n",
    "    )\n",
    "    t0 = time.time()\n",
    "    metrics = trainer.train(\n",
    "        num_iterations=VALIDATION_ITERS,\n",
    "        checkpoint_interval_minutes=999,\n",
    "        resume=False,\n",
    "        print_interval=2,\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # Extract live population from trainer state\n",
    "    ps = trainer._parallel_state\n",
    "    alive = np.array(ps.env_state.agent_alive)       # (3, 32, 64)\n",
    "    pop_per_seed = alive.sum(axis=(1, 2)) / alive.shape[1]  # mean across envs\n",
    "    final_pops = [float(p) for p in pop_per_seed]\n",
    "\n",
    "    # Quick eval: 1 episode per condition with seed 0's params\n",
    "    network = ActorCritic(hidden_dims=(64, 64), num_actions=6)\n",
    "    eval_key = jax.random.PRNGKey(42)\n",
    "    seed0_params = jax.tree.map(lambda x: x[0], ps.params)\n",
    "    eval_result = run_hidden_food_eval(network, seed0_params, config, eval_key, num_episodes=1)\n",
    "\n",
    "    validation_results[cond_name] = {\n",
    "        'metrics': metrics, 'elapsed': elapsed,\n",
    "        'final_pops': final_pops, 'eval': eval_result,\n",
    "    }\n",
    "    print(f\"\\n{cond_name}: {elapsed:.0f}s\")\n",
    "    print(f\"  Final populations (per seed, mean across envs): {[f'{p:.1f}' for p in final_pops]}\")\n",
    "    print(f\"  Eval reward: {eval_result['total_reward']:.1f}\")\n",
    "    print(f\"  Eval HF revealed: {eval_result['hidden_food_revealed']}\")\n",
    "    print(f\"  Eval HF collected: {eval_result['hidden_food_collected']:.1f}\")\n",
    "    print(f\"  Eval final pop: {eval_result['final_population']}\")\n",
    "\n",
    "    del trainer\n",
    "    gc.collect()\n",
    "    jax.clear_caches()\n",
    "\n",
    "# --- Decision gate ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION DECISION GATE\")\n",
    "print(\"=\"*60)\n",
    "max_pop = 0\n",
    "for cond_name, _ in CONDITIONS:\n",
    "    pops = validation_results[cond_name]['final_pops']\n",
    "    mean_pop = np.mean(pops)\n",
    "    hfr = validation_results[cond_name]['eval']['hidden_food_revealed']\n",
    "    print(f\"{cond_name:<25} mean population: {mean_pop:.1f}  HF revealed: {hfr}\")\n",
    "    max_pop = max(max_pop, mean_pop)\n",
    "\n",
    "if max_pop > 10:\n",
    "    print(\"\\n\\u2705 PASS: At least one condition sustains population > 10. Proceed to Phase 2.\")\n",
    "else:\n",
    "    print(\"\\n\\u274c FAIL: All conditions have dangerously low populations.\")\n",
    "    print(\"  Fallback 1: Increase num_food from 10 to 15 (slightly less harsh)\")\n",
    "    print(\"  Fallback 2: Increase food_energy from 60 to 80 (more reward per food)\")\n",
    "    print(\"  Fallback 3: Reduce required_agents from 5 to 4 (easier hidden food)\")\n",
    "    print(\"  Apply ONE change at a time and re-run validation.\")\n",
    "\n",
    "all_hfr = [validation_results[c]['eval']['hidden_food_revealed'] for c, _ in CONDITIONS]\n",
    "if all(h == 0 for h in all_hfr):\n",
    "    print(\"\\nNOTE: No hidden food revealed in any condition at 2M steps.\")\n",
    "    print(\"  This is expected \\u2014 coordination may take longer to emerge.\")\n",
    "    print(\"  If populations are healthy, proceed. HF coordination is the 10M-step question.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 \\u2014 Full Training\n",
    "\n",
    "15 seeds per condition (45 total), 10M steps each.\n",
    "\n",
    "**Execution plan**:\n",
    "- 5 batches x 3 seeds per condition\n",
    "- Seed IDs: OFF [50-64], Presence [0-14], Smart [100-114]\n",
    "- Resume-safe with checkpoint detection\n",
    "- Memory cleanup between every batch\n",
    "- Population crash detection after each batch\n",
    "- Checkpoints saved to Google Drive every 60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, gc, pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "TOTAL_STEPS = 10_000_000\n",
    "SEEDS_PER_BATCH = 3\n",
    "TOTAL_BATCHES = 5\n",
    "CHECKPOINT_INTERVAL_MINUTES = 60\n",
    "RESUME = True\n",
    "\n",
    "steps_per_iter = NUM_ENVS * NUM_STEPS * MAX_AGENTS  # 262,144\n",
    "num_iterations = TOTAL_STEPS // steps_per_iter       # 38\n",
    "\n",
    "CHECKPOINT_BASE = '/content/drive/MyDrive/emergence-lab'\n",
    "CHECKPOINT_DIRS = {\n",
    "    'field_off': f'{CHECKPOINT_BASE}/smart_field_off',\n",
    "    'field_on_presence': f'{CHECKPOINT_BASE}/smart_field_presence',\n",
    "    'field_on_smart': f'{CHECKPOINT_BASE}/smart_field_smart',\n",
    "}\n",
    "\n",
    "# Seed ID ranges (non-overlapping)\n",
    "SEED_RANGES = {\n",
    "    'field_off': list(range(50, 65)),           # [50..64]\n",
    "    'field_on_presence': list(range(0, 15)),     # [0..14]\n",
    "    'field_on_smart': list(range(100, 115)),     # [100..114]\n",
    "}\n",
    "\n",
    "print(f\"Steps per iteration: {steps_per_iter:,}\")\n",
    "print(f\"Total iterations: {num_iterations}\")\n",
    "print(f\"Seeds per condition: {SEEDS_PER_BATCH * TOTAL_BATCHES}\")\n",
    "print(f\"Total training runs: {3 * SEEDS_PER_BATCH * TOTAL_BATCHES}\")\n",
    "\n",
    "for condition_name in ['field_off', 'field_on_presence', 'field_on_smart']:\n",
    "    config = build_config(condition_name)\n",
    "    config.train.total_steps = TOTAL_STEPS\n",
    "    checkpoint_dir_base = CHECKPOINT_DIRS[condition_name]\n",
    "    os.makedirs(checkpoint_dir_base, exist_ok=True)\n",
    "    all_seeds = SEED_RANGES[condition_name]\n",
    "\n",
    "    all_results = []\n",
    "    cond_start = time.time()\n",
    "\n",
    "    for batch_number in range(TOTAL_BATCHES):\n",
    "        seed_ids = all_seeds[\n",
    "            batch_number * SEEDS_PER_BATCH : (batch_number + 1) * SEEDS_PER_BATCH\n",
    "        ]\n",
    "        checkpoint_dir = f'{checkpoint_dir_base}/batch_{batch_number}'\n",
    "        batch_start = time.time()\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{condition_name.upper()} - Batch {batch_number+1}/{TOTAL_BATCHES} - Seeds {seed_ids}\")\n",
    "        elapsed_total = time.time() - cond_start\n",
    "        if batch_number > 0:\n",
    "            avg_per_batch = elapsed_total / batch_number\n",
    "            remaining = avg_per_batch * (TOTAL_BATCHES - batch_number)\n",
    "            eta = datetime.now() + timedelta(seconds=remaining)\n",
    "            print(f\"ETA: {eta.strftime('%H:%M:%S')} ({remaining/60:.0f} min remaining)\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        try:\n",
    "            trainer = ParallelTrainer(\n",
    "                config=config, num_seeds=SEEDS_PER_BATCH,\n",
    "                seed_ids=seed_ids, checkpoint_dir=checkpoint_dir,\n",
    "                master_seed=42 + batch_number * 1000,\n",
    "            )\n",
    "            metrics = trainer.train(\n",
    "                num_iterations=num_iterations,\n",
    "                checkpoint_interval_minutes=CHECKPOINT_INTERVAL_MINUTES,\n",
    "                resume=RESUME,\n",
    "                print_interval=5,\n",
    "            )\n",
    "            batch_time = time.time() - batch_start\n",
    "\n",
    "            # Population crash detection\n",
    "            ps = trainer._parallel_state\n",
    "            alive = np.array(ps.env_state.agent_alive)\n",
    "            pop_per_seed = alive.sum(axis=(1, 2)) / alive.shape[1]\n",
    "            batch_pops = [float(p) for p in pop_per_seed]\n",
    "            print(f\"  Final populations: {[f'{p:.0f}' for p in batch_pops]}\")\n",
    "            if all(p < 3 for p in batch_pops):\n",
    "                print(f\"  \\u26a0\\ufe0f WARNING: All seeds in batch {batch_number} have near-zero population!\")\n",
    "                print(f\"  Population may have crashed. Check environment parameters.\")\n",
    "\n",
    "            all_results.append({\n",
    "                'batch': batch_number, 'seed_ids': seed_ids,\n",
    "                'metrics': metrics, 'success': True,\n",
    "                'time_seconds': batch_time, 'final_pops': batch_pops,\n",
    "            })\n",
    "            print(f\"Batch {batch_number} done in {batch_time/60:.1f} min\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in batch {batch_number}: {e}\")\n",
    "            import traceback; traceback.print_exc()\n",
    "            all_results.append({\n",
    "                'batch': batch_number, 'seed_ids': seed_ids,\n",
    "                'success': False, 'error': str(e),\n",
    "            })\n",
    "        finally:\n",
    "            try: del trainer\n",
    "            except: pass\n",
    "            gc.collect()\n",
    "            jax.clear_caches()\n",
    "\n",
    "    cond_time = time.time() - cond_start\n",
    "    summary_path = f'{checkpoint_dir_base}/training_summary.pkl'\n",
    "    with open(summary_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'all_results': all_results,\n",
    "            'total_time_seconds': cond_time,\n",
    "            'condition': condition_name,\n",
    "            'total_steps': TOTAL_STEPS,\n",
    "            'config': {\n",
    "                'grid_size': config.env.grid_size,\n",
    "                'num_food': config.env.num_food,\n",
    "                'food_energy': config.evolution.food_energy,\n",
    "                'num_hidden': config.env.hidden_food.num_hidden,\n",
    "                'required_agents': config.env.hidden_food.required_agents,\n",
    "                'hidden_food_value_multiplier': config.env.hidden_food.hidden_food_value_multiplier,\n",
    "                'field_enabled': condition_name != 'field_off',\n",
    "                'write_mode': config.field.write_mode,\n",
    "                'max_agents': config.evolution.max_agents,\n",
    "            },\n",
    "        }, f)\n",
    "    print(f\"\\n{condition_name} COMPLETE in {cond_time/3600:.1f} hours\")\n",
    "    print(f\"Summary saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3 \\u2014 Analysis\n",
    "\n",
    "Load checkpoints from all 3 conditions, run evaluation episodes, compute statistics, and generate publication-quality figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport json, pickle, gc, os\nimport glob as glob_mod\nfrom pathlib import Path\nfrom datetime import datetime\nfrom scipy import stats as scipy_stats\n\nimport jax\nimport jax.numpy as jnp\n\nfrom src.configs import (\n    Config, TrainingMode, HiddenFoodConfig, EnvConfig, FieldConfig,\n    AgentConfig, TrainConfig, LogConfig, AnalysisConfig,\n    EvolutionConfig, SpecializationConfig, FreezeEvolveConfig, ArchiveConfig,\n)\nfrom src.agents.network import ActorCritic\nfrom src.agents.policy import get_deterministic_actions\nfrom src.environment.env import reset, step\nfrom src.environment.obs import get_observations\nfrom src.training.checkpointing import load_checkpoint\nfrom src.analysis.specialization import compute_weight_divergence\nfrom src.analysis.statistics import (\n    compute_iqm, compare_methods, welch_t_test,\n    mann_whitney_test, probability_of_improvement,\n)\n\n%matplotlib inline\nfrom src.analysis.paper_figures import setup_publication_style, save_figure\n\nsetup_publication_style()\n\nOUTPUT_DIR = '/content/drive/MyDrive/emergence-lab/smart_field_results'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# --- Condition labels and colors ---\nCOND_NAMES = ['field_off', 'field_on_presence', 'field_on_smart']\nCOND_LABELS = {'field_off': 'Field OFF', 'field_on_presence': 'Presence', 'field_on_smart': 'Smart'}\nCOND_COLORS = {'field_off': '#BBBBBB', 'field_on_presence': '#009988', 'field_on_smart': '#EE7733'}\n\n\ndef reconstruct_config(d):\n    \"\"\"Convert plain dict from load_checkpoint() back to Config dataclass.\"\"\"\n    if isinstance(d, Config):\n        return d\n\n    # Env config - handle nested hidden_food dict\n    env_d = dict(d.get('env', {}))\n    if 'hidden_food' in env_d and isinstance(env_d['hidden_food'], dict):\n        env_d['hidden_food'] = HiddenFoodConfig(**env_d['hidden_food'])\n\n    # Train config - handle TrainingMode enum\n    train_d = dict(d.get('train', {}))\n    if 'training_mode' in train_d and isinstance(train_d['training_mode'], str):\n        train_d['training_mode'] = TrainingMode(train_d['training_mode'])\n\n    # Agent config - handle hidden_dims tuple\n    agent_d = dict(d.get('agent', {}))\n    if 'hidden_dims' in agent_d and isinstance(agent_d['hidden_dims'], list):\n        agent_d['hidden_dims'] = tuple(agent_d['hidden_dims'])\n\n    # Field config - handle write_mode backward compatibility\n    field_d = dict(d.get('field', {}))\n    if 'write_mode' not in field_d:\n        field_d['write_mode'] = 'presence'  # default for pre-write_mode checkpoints\n\n    return Config(\n        env=EnvConfig(**env_d),\n        field=FieldConfig(**field_d),\n        agent=AgentConfig(**agent_d),\n        train=TrainConfig(**train_d),\n        log=LogConfig(**d.get('log', {})),\n        analysis=AnalysisConfig(**d.get('analysis', {})),\n        evolution=EvolutionConfig(**d.get('evolution', {})),\n        specialization=SpecializationConfig(**d.get('specialization', {})),\n        freeze_evolve=FreezeEvolveConfig(**d.get('freeze_evolve', {})),\n        archive=ArchiveConfig(**d.get('archive', {})),\n    )\n\n\ndef discover_checkpoints(base_dir, max_batches=20):\n    \"\"\"Find all checkpoint paths under base_dir/batch_*/seed_*/step_*.pkl.\"\"\"\n    paths = []\n    for batch_idx in range(max_batches):\n        batch_dir = os.path.join(base_dir, f'batch_{batch_idx}')\n        if not os.path.exists(batch_dir):\n            continue\n        for seed_dir_name in sorted(os.listdir(batch_dir)):\n            seed_path = os.path.join(batch_dir, seed_dir_name)\n            if not os.path.isdir(seed_path):\n                continue\n            pkl_files = glob_mod.glob(os.path.join(seed_path, 'step_*.pkl'))\n            if pkl_files:\n                paths.append(sorted(pkl_files)[-1])  # Latest step\n    return paths\n\n\ndef load_training_summary(base_dir):\n    \"\"\"Load training_summary.pkl and extract per-seed rewards + populations.\"\"\"\n    summary_path = os.path.join(base_dir, 'training_summary.pkl')\n    if not os.path.exists(summary_path):\n        return None, None\n    with open(summary_path, 'rb') as f:\n        summary = pickle.load(f)\n    rewards = []\n    populations = []\n    for batch in summary['all_results']:\n        if not batch.get('success', True):\n            continue\n        if 'metrics' in batch and 'mean_reward' in batch['metrics']:\n            rewards.extend(batch['metrics']['mean_reward'])\n        if 'metrics' in batch and 'population_size' in batch['metrics']:\n            populations.extend(batch['metrics']['population_size'])\n    if rewards:\n        return np.array(rewards), np.array(populations, dtype=float)\n    return None, None\n\n\ndef load_seed_data(ckpt_path):\n    \"\"\"Load checkpoint, extract network + config, free full checkpoint.\"\"\"\n    ckpt = load_checkpoint(ckpt_path)\n    config = reconstruct_config(ckpt['config'])\n    # agent_params from checkpoint: (num_envs, max_agents, ...)\n    # Take env 0 for divergence analysis: (max_agents, ...)\n    agent_params_env0 = jax.tree_util.tree_map(lambda x: x[0], ckpt['agent_params'])\n    network = ActorCritic(\n        hidden_dims=tuple(config.agent.hidden_dims), num_actions=6\n    )\n    result = {\n        'params': ckpt['params'],\n        'agent_params': agent_params_env0,\n        'config': config,\n        'network': network,\n        'seed_id': ckpt.get('seed_id', -1),\n    }\n    del ckpt\n    return result\n\n\n# --- Load checkpoints ---\nCHECKPOINT_BASE = '/content/drive/MyDrive/emergence-lab'\n\ncond_dirs = {\n    'field_off': f'{CHECKPOINT_BASE}/smart_field_off',\n    'field_on_presence': f'{CHECKPOINT_BASE}/smart_field_presence',\n    'field_on_smart': f'{CHECKPOINT_BASE}/smart_field_smart',\n}\n\ncond_ckpt_paths = {}\ncond_rewards = {}\ncond_populations = {}\n\nfor cond in COND_NAMES:\n    cond_ckpt_paths[cond] = discover_checkpoints(cond_dirs[cond])\n    cond_rewards[cond], cond_populations[cond] = load_training_summary(cond_dirs[cond])\n    n_ckpt = len(cond_ckpt_paths[cond])\n    print(f\"{COND_LABELS[cond]:<12} checkpoints: {n_ckpt}/15\", end=\"\")\n    if cond_rewards[cond] is not None:\n        print(f\"  training reward mean={np.mean(cond_rewards[cond]):.4f}\")\n    else:\n        print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Reward Statistics (ANOVA + pairwise) ---\n",
    "\n",
    "# Check we have training data for all conditions\n",
    "have_rewards = all(cond_rewards[c] is not None for c in COND_NAMES)\n",
    "\n",
    "if have_rewards:\n",
    "    # ANOVA across 3 conditions\n",
    "    f_stat, anova_p = scipy_stats.f_oneway(\n",
    "        cond_rewards['field_off'],\n",
    "        cond_rewards['field_on_presence'],\n",
    "        cond_rewards['field_on_smart'],\n",
    "    )\n",
    "    print(f\"ANOVA: F={f_stat:.3f}, p={anova_p:.6f}\")\n",
    "    if anova_p < 0.05:\n",
    "        print(\"  Significant difference across conditions.\")\n",
    "    else:\n",
    "        print(\"  No significant difference across conditions.\")\n",
    "\n",
    "    # Pairwise comparisons\n",
    "    PAIRS = [\n",
    "        ('field_on_smart', 'field_on_presence', 'Smart vs Presence (KEY)'),\n",
    "        ('field_on_smart', 'field_off', 'Smart vs OFF'),\n",
    "        ('field_on_presence', 'field_off', 'Presence vs OFF'),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n{'Comparison':<35} {'t':>8} {'p':>10} {'d':>8} {'P(A>B)':>8}\")\n",
    "    print(\"-\" * 75)\n",
    "    for cond_a, cond_b, label in PAIRS:\n",
    "        welch = welch_t_test(cond_rewards[cond_a], cond_rewards[cond_b])\n",
    "        poi = probability_of_improvement(cond_rewards[cond_a], cond_rewards[cond_b], seed=42)\n",
    "        sig = \"***\" if welch.p_value < 0.001 else \"**\" if welch.p_value < 0.01 else \"*\" if welch.p_value < 0.05 else \"\"\n",
    "        print(f\"{label:<35} {welch.statistic:>8.3f} {welch.p_value:>10.4f} {welch.effect_size:>8.3f} {poi['prob_x_better']:>8.3f} {sig}\")\n",
    "\n",
    "    # IQM comparison\n",
    "    print(\"\\nIQM Comparison:\")\n",
    "    score_dict = {COND_LABELS[c]: cond_rewards[c] for c in COND_NAMES}\n",
    "    comparison = compare_methods(score_dict, alpha=0.05, n_bootstrap=10000, seed=42)\n",
    "    print(comparison.summary)\n",
    "else:\n",
    "    print(\"Training summaries not found for all conditions. Run training cells first.\")\n",
    "    comparison = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Comparison Plots (3 conditions) ---\n",
    "\n",
    "if have_rewards:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Panel 1: IQM bars with CI\n",
    "    ax = axes[0]\n",
    "    iqm_vals = {}\n",
    "    for i, cond in enumerate(COND_NAMES):\n",
    "        iqm_vals[cond] = compute_iqm(cond_rewards[cond], seed=42)\n",
    "    x_pos = np.arange(len(COND_NAMES))\n",
    "    bars = ax.bar(\n",
    "        x_pos,\n",
    "        [iqm_vals[c].iqm for c in COND_NAMES],\n",
    "        color=[COND_COLORS[c] for c in COND_NAMES],\n",
    "        edgecolor='black', linewidth=0.8,\n",
    "        tick_label=[COND_LABELS[c] for c in COND_NAMES],\n",
    "    )\n",
    "    ax.errorbar(\n",
    "        x_pos,\n",
    "        [iqm_vals[c].iqm for c in COND_NAMES],\n",
    "        yerr=[\n",
    "            [iqm_vals[c].iqm - iqm_vals[c].ci_lower for c in COND_NAMES],\n",
    "            [iqm_vals[c].ci_upper - iqm_vals[c].iqm for c in COND_NAMES],\n",
    "        ],\n",
    "        fmt='none', color='black', capsize=5,\n",
    "    )\n",
    "    ax.set_ylabel('IQM Reward')\n",
    "    ax.set_title('Training Reward (IQM + 95% CI)')\n",
    "\n",
    "    # Panel 2: Violin + swarm\n",
    "    ax = axes[1]\n",
    "    data_list = [cond_rewards[c] for c in COND_NAMES]\n",
    "    parts = ax.violinplot(data_list, positions=x_pos, showmeans=True, showmedians=True)\n",
    "    for i, pc in enumerate(parts['bodies']):\n",
    "        pc.set_facecolor(COND_COLORS[COND_NAMES[i]])\n",
    "        pc.set_alpha(0.6)\n",
    "    for i, cond in enumerate(COND_NAMES):\n",
    "        jitter = np.random.default_rng(42 + i).uniform(-0.1, 0.1, len(cond_rewards[cond]))\n",
    "        ax.scatter(i + jitter, cond_rewards[cond], c=COND_COLORS[cond], s=15, alpha=0.7, zorder=3)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([COND_LABELS[c] for c in COND_NAMES])\n",
    "    ax.set_ylabel('Final Reward')\n",
    "    ax.set_title('Reward Distribution')\n",
    "\n",
    "    # Panel 3: Population distribution\n",
    "    ax = axes[2]\n",
    "    have_pops = all(cond_populations[c] is not None for c in COND_NAMES)\n",
    "    if have_pops:\n",
    "        all_pop_vals = np.concatenate([cond_populations[c] for c in COND_NAMES])\n",
    "        bins = np.linspace(all_pop_vals.min(), all_pop_vals.max(), 20)\n",
    "        for cond in COND_NAMES:\n",
    "            ax.hist(cond_populations[cond], bins=bins, alpha=0.5,\n",
    "                    color=COND_COLORS[cond], label=COND_LABELS[cond], edgecolor='black')\n",
    "        ax.set_xlabel('Final Population')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title('Population Distribution')\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No population data', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "    fig.suptitle('Smart Field Test: Training Comparison', fontsize=16, y=1.02)\n",
    "    fig.tight_layout()\n",
    "    save_figure(fig, os.path.join(OUTPUT_DIR, 'training_comparison'))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No training data to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load & Eval All Checkpoints + Weight Divergence ---\n",
    "\n",
    "cond_hf_eval = {c: [] for c in COND_NAMES}\n",
    "cond_divergence = {c: [] for c in COND_NAMES}\n",
    "\n",
    "for cond in COND_NAMES:\n",
    "    ckpt_paths = cond_ckpt_paths[cond]\n",
    "    label = COND_LABELS[cond]\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Evaluating {label}: {len(ckpt_paths)} seeds\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    for i, ckpt_path in enumerate(ckpt_paths):\n",
    "        print(f\"  [{label}] Eval seed {i+1}/{len(ckpt_paths)}: {os.path.basename(ckpt_path)}\")\n",
    "        seed_data = load_seed_data(ckpt_path)\n",
    "        key = jax.random.PRNGKey(42 + i)\n",
    "\n",
    "        hf_result = run_hidden_food_eval(\n",
    "            seed_data['network'], seed_data['params'],\n",
    "            seed_data['config'], key, num_episodes=1,\n",
    "        )\n",
    "        hf_result['seed_id'] = seed_data['seed_id']\n",
    "        cond_hf_eval[cond].append(hf_result)\n",
    "\n",
    "        # Compute weight divergence\n",
    "        max_agents = seed_data['config'].evolution.max_agents\n",
    "        alive_mask = np.ones(max_agents, dtype=bool)\n",
    "        div = compute_weight_divergence(seed_data['agent_params'], alive_mask)\n",
    "        cond_divergence[cond].append({\n",
    "            'seed_id': seed_data['seed_id'],\n",
    "            'mean_divergence': float(div['mean_divergence']),\n",
    "            'max_divergence': float(div['max_divergence']),\n",
    "        })\n",
    "\n",
    "        del seed_data\n",
    "        gc.collect()\n",
    "\n",
    "        # Intermediate save after each seed\n",
    "        progress_path = os.path.join(OUTPUT_DIR, f'eval_progress_{cond}.pkl')\n",
    "        with open(progress_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'condition': cond,\n",
    "                'completed_seeds': i + 1,\n",
    "                'total_seeds': len(ckpt_paths),\n",
    "                'hf_eval': list(cond_hf_eval[cond]),\n",
    "                'divergence': list(cond_divergence[cond]),\n",
    "            }, f)\n",
    "\n",
    "# Build numpy arrays per condition per metric\n",
    "EVAL_METRICS = [\n",
    "    'total_reward', 'hidden_food_revealed', 'hidden_food_collected',\n",
    "    'regular_food_collected', 'hidden_food_energy', 'regular_food_energy',\n",
    "    'final_population',\n",
    "]\n",
    "\n",
    "cond_arrays = {}\n",
    "for cond in COND_NAMES:\n",
    "    cond_arrays[cond] = {}\n",
    "    for metric in EVAL_METRICS:\n",
    "        cond_arrays[cond][metric] = np.array([r[metric] for r in cond_hf_eval[cond]])\n",
    "    cond_arrays[cond]['mean_divergence'] = np.array(\n",
    "        [d['mean_divergence'] for d in cond_divergence[cond]]\n",
    "    )\n",
    "\n",
    "for cond in COND_NAMES:\n",
    "    n = len(cond_hf_eval[cond])\n",
    "    print(f\"{COND_LABELS[cond]}: {n} seeds evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hidden Food Stats + Grouped Bar/Violin Plots ---\n",
    "\n",
    "PLOT_METRICS = [\n",
    "    ('hidden_food_revealed', 'Hidden Food Revealed'),\n",
    "    ('hidden_food_collected', 'Hidden Food Collected'),\n",
    "    ('regular_food_collected', 'Regular Food Collected'),\n",
    "    ('total_reward', 'Total Reward'),\n",
    "    ('final_population', 'Final Population'),\n",
    "    ('mean_divergence', 'Weight Divergence'),\n",
    "]\n",
    "\n",
    "# --- Statistical table (ANOVA + pairwise per metric) ---\n",
    "print(f\"{'Metric':<25} {'OFF':>8} {'Pres':>8} {'Smart':>8} {'F':>8} {'p(ANOVA)':>10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "stat_results = {}\n",
    "for metric, _ in PLOT_METRICS:\n",
    "    vals = {c: cond_arrays[c][metric] for c in COND_NAMES}\n",
    "    means = {c: np.mean(vals[c]) for c in COND_NAMES}\n",
    "\n",
    "    # Skip ANOVA if all values are zero/constant\n",
    "    all_std_zero = all(np.std(vals[c]) == 0 for c in COND_NAMES)\n",
    "    if all_std_zero:\n",
    "        f_stat, anova_p = 0.0, 1.0\n",
    "    else:\n",
    "        f_stat, anova_p = scipy_stats.f_oneway(\n",
    "            vals['field_off'], vals['field_on_presence'], vals['field_on_smart']\n",
    "        )\n",
    "\n",
    "    sig = \"***\" if anova_p < 0.001 else \"**\" if anova_p < 0.01 else \"*\" if anova_p < 0.05 else \"\"\n",
    "    print(f\"{metric:<25} {means['field_off']:>8.2f} {means['field_on_presence']:>8.2f} {means['field_on_smart']:>8.2f} {f_stat:>8.2f} {anova_p:>10.4f} {sig}\")\n",
    "\n",
    "    # Pairwise t-tests\n",
    "    pairwise = {}\n",
    "    for cond_a, cond_b, label in PAIRS:\n",
    "        if np.std(vals[cond_a]) == 0 and np.std(vals[cond_b]) == 0:\n",
    "            pairwise[label] = {'t': 0.0, 'p': 1.0, 'd': 0.0}\n",
    "        else:\n",
    "            w = welch_t_test(vals[cond_a], vals[cond_b])\n",
    "            pairwise[label] = {'t': w.statistic, 'p': w.p_value, 'd': w.effect_size}\n",
    "\n",
    "    stat_results[metric] = {\n",
    "        'means': means,\n",
    "        'stds': {c: np.std(vals[c]) for c in COND_NAMES},\n",
    "        'anova_f': f_stat, 'anova_p': anova_p,\n",
    "        'pairwise': pairwise,\n",
    "    }\n",
    "\n",
    "print(\"\\n* p<0.05  ** p<0.01  *** p<0.001\")\n",
    "\n",
    "# --- Grouped bar chart ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "bar_width = 0.25\n",
    "x_pos = np.arange(1)  # single group\n",
    "\n",
    "for idx, (metric, title) in enumerate(PLOT_METRICS):\n",
    "    ax = axes_flat[idx]\n",
    "    for j, cond in enumerate(COND_NAMES):\n",
    "        vals = cond_arrays[cond][metric]\n",
    "        mean_val = np.mean(vals)\n",
    "        std_val = np.std(vals)\n",
    "        ax.bar(\n",
    "            j * bar_width, mean_val, bar_width,\n",
    "            yerr=std_val, color=COND_COLORS[cond],\n",
    "            edgecolor='black', linewidth=0.8, capsize=4,\n",
    "            label=COND_LABELS[cond] if idx == 0 else None,\n",
    "        )\n",
    "    ax.set_xticks([j * bar_width for j in range(3)])\n",
    "    ax.set_xticklabels([COND_LABELS[c] for c in COND_NAMES], fontsize=9)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Annotate ANOVA p-value\n",
    "    sr = stat_results[metric]\n",
    "    sig = \"***\" if sr['anova_p'] < 0.001 else \"**\" if sr['anova_p'] < 0.01 else \"*\" if sr['anova_p'] < 0.05 else \"ns\"\n",
    "    ax.annotate(f\"ANOVA p={sr['anova_p']:.3f} {sig}\",\n",
    "                xy=(0.5, 0.95), xycoords='axes fraction', ha='center', va='top', fontsize=8)\n",
    "\n",
    "axes_flat[0].legend(loc='upper left', fontsize=9)\n",
    "fig.suptitle('Smart Field Test: Eval Metrics (Grouped Bars)', fontsize=16, y=1.02)\n",
    "fig.tight_layout()\n",
    "save_figure(fig, os.path.join(OUTPUT_DIR, 'eval_grouped_bars'))\n",
    "plt.show()\n",
    "\n",
    "# --- Violin plots ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, (metric, title) in enumerate(PLOT_METRICS):\n",
    "    ax = axes_flat[idx]\n",
    "    data_list = [cond_arrays[c][metric] for c in COND_NAMES]\n",
    "\n",
    "    # Check if all data is zero\n",
    "    if all(np.all(d == 0) for d in data_list):\n",
    "        for j, cond in enumerate(COND_NAMES):\n",
    "            ax.bar(j, 0, color=COND_COLORS[cond], edgecolor='black', linewidth=0.8)\n",
    "        ax.annotate('All zero', xy=(0.5, 0.5), xycoords='axes fraction',\n",
    "                    ha='center', va='center', fontsize=9, color='gray')\n",
    "    else:\n",
    "        parts = ax.violinplot(data_list, positions=range(3), showmeans=True, showmedians=True)\n",
    "        for j, pc in enumerate(parts['bodies']):\n",
    "            pc.set_facecolor(COND_COLORS[COND_NAMES[j]])\n",
    "            pc.set_alpha(0.6)\n",
    "        # Swarm overlay\n",
    "        for j, cond in enumerate(COND_NAMES):\n",
    "            jitter = np.random.default_rng(42 + j).uniform(-0.1, 0.1, len(data_list[j]))\n",
    "            ax.scatter(j + jitter, data_list[j], c=COND_COLORS[cond], s=12, alpha=0.7, zorder=3)\n",
    "\n",
    "    ax.set_xticks(range(3))\n",
    "    ax.set_xticklabels([COND_LABELS[c] for c in COND_NAMES], fontsize=9)\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig.suptitle('Smart Field Test: Eval Metrics (Violin)', fontsize=16, y=1.02)\n",
    "fig.tight_layout()\n",
    "save_figure(fig, os.path.join(OUTPUT_DIR, 'eval_violins'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Divergence & Correlation Plots ---\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 11))\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=COND_COLORS[c],\n",
    "           markersize=8, label=COND_LABELS[c])\n",
    "    for c in COND_NAMES\n",
    "]\n",
    "\n",
    "# Panel 1: Weight divergence histogram (3 conditions overlaid)\n",
    "ax = axes[0, 0]\n",
    "all_divs = [cond_arrays[c]['mean_divergence'] for c in COND_NAMES]\n",
    "if any(len(d) > 0 for d in all_divs):\n",
    "    all_vals = np.concatenate([d for d in all_divs if len(d) > 0])\n",
    "    bins = np.linspace(all_vals.min(), all_vals.max(), 20)\n",
    "    for cond in COND_NAMES:\n",
    "        if len(cond_arrays[cond]['mean_divergence']) > 0:\n",
    "            ax.hist(cond_arrays[cond]['mean_divergence'], bins=bins, alpha=0.5,\n",
    "                    color=COND_COLORS[cond], label=COND_LABELS[cond], edgecolor='black')\n",
    "    ax.set_xlabel('Mean Weight Divergence')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Weight Divergence Distribution')\n",
    "    ax.legend()\n",
    "\n",
    "# Panel 2: Population histogram (3 conditions overlaid)\n",
    "ax = axes[0, 1]\n",
    "all_pops_list = [cond_arrays[c]['final_population'] for c in COND_NAMES]\n",
    "if any(len(p) > 0 for p in all_pops_list):\n",
    "    all_pop_vals = np.concatenate([p for p in all_pops_list if len(p) > 0])\n",
    "    bins = np.linspace(all_pop_vals.min(), all_pop_vals.max(), 20)\n",
    "    for cond in COND_NAMES:\n",
    "        if len(cond_arrays[cond]['final_population']) > 0:\n",
    "            ax.hist(cond_arrays[cond]['final_population'], bins=bins, alpha=0.5,\n",
    "                    color=COND_COLORS[cond], label=COND_LABELS[cond], edgecolor='black')\n",
    "    ax.set_xlabel('Final Population (eval)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Eval Population Distribution')\n",
    "    ax.legend()\n",
    "\n",
    "# Panel 3: Scatter — HF collected vs divergence (color by condition)\n",
    "ax = axes[1, 0]\n",
    "for cond in COND_NAMES:\n",
    "    hf = cond_arrays[cond]['hidden_food_collected']\n",
    "    div = cond_arrays[cond]['mean_divergence']\n",
    "    if len(hf) > 0:\n",
    "        ax.scatter(div, hf, c=COND_COLORS[cond], s=30, alpha=0.7,\n",
    "                   edgecolors='black', linewidth=0.5)\n",
    "all_hf = np.concatenate([cond_arrays[c]['hidden_food_collected'] for c in COND_NAMES if len(cond_arrays[c]['hidden_food_collected']) > 0])\n",
    "all_div = np.concatenate([cond_arrays[c]['mean_divergence'] for c in COND_NAMES if len(cond_arrays[c]['mean_divergence']) > 0])\n",
    "if len(all_div) > 2 and np.std(all_div) > 0 and np.std(all_hf) > 0:\n",
    "    r, p = scipy_stats.pearsonr(all_div, all_hf)\n",
    "    ax.set_title(f'HF Collected vs Divergence (r={r:.3f}, p={p:.3f})')\n",
    "else:\n",
    "    ax.set_title('HF Collected vs Divergence')\n",
    "ax.set_xlabel('Mean Weight Divergence')\n",
    "ax.set_ylabel('Hidden Food Collected')\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "# Panel 4: Scatter — reward vs population (color by condition)\n",
    "ax = axes[1, 1]\n",
    "for cond in COND_NAMES:\n",
    "    rew = cond_arrays[cond]['total_reward']\n",
    "    pop = cond_arrays[cond]['final_population'].astype(float)\n",
    "    if len(rew) > 0:\n",
    "        ax.scatter(pop, rew, c=COND_COLORS[cond], s=30, alpha=0.7,\n",
    "                   edgecolors='black', linewidth=0.5)\n",
    "all_rew = np.concatenate([cond_arrays[c]['total_reward'] for c in COND_NAMES if len(cond_arrays[c]['total_reward']) > 0])\n",
    "all_pop = np.concatenate([cond_arrays[c]['final_population'].astype(float) for c in COND_NAMES if len(cond_arrays[c]['final_population']) > 0])\n",
    "if len(all_pop) > 2 and np.std(all_pop) > 0 and np.std(all_rew) > 0:\n",
    "    r, p = scipy_stats.pearsonr(all_pop, all_rew)\n",
    "    ax.set_title(f'Reward vs Population (r={r:.3f}, p={p:.3f})')\n",
    "else:\n",
    "    ax.set_title('Reward vs Population')\n",
    "ax.set_xlabel('Final Population')\n",
    "ax.set_ylabel('Total Reward')\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "fig.suptitle('Smart Field Test: Divergence & Correlations', fontsize=16, y=1.02)\n",
    "fig.tight_layout()\n",
    "save_figure(fig, os.path.join(OUTPUT_DIR, 'divergence_correlation'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary Report ---\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "n_seeds = {c: len(cond_hf_eval[c]) for c in COND_NAMES}\n",
    "\n",
    "report = f\"\"\"# Smart Field Test: Results Summary\n",
    "\n",
    "**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "## Experimental Setup\n",
    "- **Grid**: 40x40, **Regular food**: 10 (scarce), **Food energy**: 60 (reduced)\n",
    "- **Hidden food**: 8 items, require 5 agents within distance 3, value 10x (600 energy each)\n",
    "- **Max agents**: 64, **Starting energy**: 200, **Reproduce threshold**: 120\n",
    "- **Steps**: 10M per seed\n",
    "- **Seeds**: {n_seeds['field_off']} OFF + {n_seeds['field_on_presence']} Presence + {n_seeds['field_on_smart']} Smart\n",
    "\n",
    "## Conditions\n",
    "| Condition | write_mode | Field params |\n",
    "|-----------|------------|-------------|\n",
    "| Field OFF | presence | diffusion=0, decay=1, write=0 |\n",
    "| Presence | presence | diffusion=0.1, decay=0.05, write=1.0 |\n",
    "| Smart | state_dependent | diffusion=0.1, decay=0.05, write=1.0 |\n",
    "\n",
    "## Eval Results (ANOVA + Pairwise)\n",
    "\n",
    "| Metric | OFF | Presence | Smart | ANOVA p |\n",
    "|--------|-----|----------|-------|---------|\n",
    "\"\"\"\n",
    "\n",
    "for metric, title in PLOT_METRICS:\n",
    "    sr = stat_results[metric]\n",
    "    sig = \"***\" if sr['anova_p'] < 0.001 else \"**\" if sr['anova_p'] < 0.01 else \"*\" if sr['anova_p'] < 0.05 else \"\"\n",
    "    report += (\n",
    "        f\"| {title} \"\n",
    "        f\"| {sr['means']['field_off']:.2f}+/-{sr['stds']['field_off']:.2f} \"\n",
    "        f\"| {sr['means']['field_on_presence']:.2f}+/-{sr['stds']['field_on_presence']:.2f} \"\n",
    "        f\"| {sr['means']['field_on_smart']:.2f}+/-{sr['stds']['field_on_smart']:.2f} \"\n",
    "        f\"| {sr['anova_p']:.4f}{sig} |\\n\"\n",
    "    )\n",
    "\n",
    "report += \"\\n### Pairwise Comparisons (Smart vs Presence = KEY)\\n\\n\"\n",
    "report += \"| Metric | Comparison | t | p | Cohen's d |\\n\"\n",
    "report += \"|--------|-----------|---|---|----------|\\n\"\n",
    "\n",
    "for metric, title in PLOT_METRICS:\n",
    "    sr = stat_results[metric]\n",
    "    for label, pw in sr['pairwise'].items():\n",
    "        sig = \"***\" if pw['p'] < 0.001 else \"**\" if pw['p'] < 0.01 else \"*\" if pw['p'] < 0.05 else \"\"\n",
    "        report += f\"| {title} | {label} | {pw['t']:.2f} | {pw['p']:.4f}{sig} | {pw['d']:.2f} |\\n\"\n",
    "\n",
    "report += \"\\n## Key Findings\\n\\n\"\n",
    "\n",
    "# Auto-generate key findings\n",
    "if 'total_reward' in stat_results:\n",
    "    sr = stat_results['total_reward']\n",
    "    if sr['anova_p'] < 0.05:\n",
    "        best = max(COND_NAMES, key=lambda c: sr['means'][c])\n",
    "        report += f\"- **{COND_LABELS[best]} has highest total reward** (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "        # Check key comparison: smart vs presence\n",
    "        pw = sr['pairwise']['Smart vs Presence (KEY)']\n",
    "        if pw['p'] < 0.05:\n",
    "            winner = 'Smart' if pw['t'] > 0 else 'Presence'\n",
    "            report += f\"- **{winner} significantly outperforms** on reward vs the other field mode (p={pw['p']:.4f}, d={pw['d']:.2f})\\n\"\n",
    "        else:\n",
    "            report += f\"- Smart vs Presence reward difference not significant (p={pw['p']:.4f})\\n\"\n",
    "    else:\n",
    "        report += f\"- No significant reward difference across conditions (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "\n",
    "if 'hidden_food_collected' in stat_results:\n",
    "    sr = stat_results['hidden_food_collected']\n",
    "    any_hf = any(sr['means'][c] > 0 for c in COND_NAMES)\n",
    "    if any_hf and sr['anova_p'] < 0.05:\n",
    "        best = max(COND_NAMES, key=lambda c: sr['means'][c])\n",
    "        report += f\"- **{COND_LABELS[best]} collects more hidden food** (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "    elif not any_hf:\n",
    "        report += \"- Neither condition achieved hidden food collection in eval episodes\\n\"\n",
    "    else:\n",
    "        report += f\"- No significant difference in hidden food collection (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "\n",
    "if 'final_population' in stat_results:\n",
    "    sr = stat_results['final_population']\n",
    "    if sr['anova_p'] < 0.05:\n",
    "        best = max(COND_NAMES, key=lambda c: sr['means'][c])\n",
    "        report += f\"- **{COND_LABELS[best]} sustains largest populations** (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "    else:\n",
    "        report += f\"- No significant population difference (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "\n",
    "if 'mean_divergence' in stat_results:\n",
    "    sr = stat_results['mean_divergence']\n",
    "    if sr['anova_p'] < 0.05:\n",
    "        best = max(COND_NAMES, key=lambda c: sr['means'][c])\n",
    "        report += f\"- **{COND_LABELS[best]} shows highest weight divergence** (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "    else:\n",
    "        report += f\"- No significant divergence difference (ANOVA p={sr['anova_p']:.4f})\\n\"\n",
    "\n",
    "report += f\"\"\"\\n## Output Files\n",
    "- Figures: `{OUTPUT_DIR}/training_comparison.{{pdf,png}}`\n",
    "- Figures: `{OUTPUT_DIR}/eval_grouped_bars.{{pdf,png}}`\n",
    "- Figures: `{OUTPUT_DIR}/eval_violins.{{pdf,png}}`\n",
    "- Figures: `{OUTPUT_DIR}/divergence_correlation.{{pdf,png}}`\n",
    "- Results: `{OUTPUT_DIR}/all_results.json`\n",
    "- Results: `{OUTPUT_DIR}/all_results.pkl`\n",
    "- Report: `{OUTPUT_DIR}/summary_report.md`\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(report))\n",
    "\n",
    "# --- Save all results ---\n",
    "json_results = {\n",
    "    'experiment': 'smart_field_test',\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'config': {\n",
    "        'grid_size': 40, 'num_food': 10, 'food_energy': 60,\n",
    "        'num_hidden': 8, 'required_agents': 5,\n",
    "        'hidden_food_value_multiplier': 10.0,\n",
    "        'max_agents': 64, 'total_steps': TOTAL_STEPS,\n",
    "    },\n",
    "    'n_seeds': n_seeds,\n",
    "    'eval_stats': {},\n",
    "}\n",
    "\n",
    "for metric, title in PLOT_METRICS:\n",
    "    sr = stat_results[metric]\n",
    "    entry = {\n",
    "        'anova_f': float(sr['anova_f']),\n",
    "        'anova_p': float(sr['anova_p']),\n",
    "    }\n",
    "    for cond in COND_NAMES:\n",
    "        entry[f'{cond}_mean'] = float(sr['means'][cond])\n",
    "        entry[f'{cond}_std'] = float(sr['stds'][cond])\n",
    "    for label, pw in sr['pairwise'].items():\n",
    "        safe_label = label.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "        entry[f'pw_{safe_label}_t'] = float(pw['t'])\n",
    "        entry[f'pw_{safe_label}_p'] = float(pw['p'])\n",
    "        entry[f'pw_{safe_label}_d'] = float(pw['d'])\n",
    "    json_results['eval_stats'][metric] = entry\n",
    "\n",
    "json_path = os.path.join(OUTPUT_DIR, 'all_results.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "print(f\"JSON saved: {json_path}\")\n",
    "\n",
    "pkl_results = {\n",
    "    **json_results,\n",
    "    'cond_hf_eval': cond_hf_eval,\n",
    "    'cond_divergence': cond_divergence,\n",
    "    'cond_rewards': {c: cond_rewards[c] for c in COND_NAMES if cond_rewards[c] is not None},\n",
    "    'cond_populations': {c: cond_populations[c] for c in COND_NAMES if cond_populations[c] is not None},\n",
    "}\n",
    "pkl_path = os.path.join(OUTPUT_DIR, 'all_results.pkl')\n",
    "with open(pkl_path, 'wb') as f:\n",
    "    pickle.dump(pkl_results, f)\n",
    "print(f\"Pickle saved: {pkl_path}\")\n",
    "\n",
    "md_path = os.path.join(OUTPUT_DIR, 'summary_report.md')\n",
    "with open(md_path, 'w') as f:\n",
    "    f.write(report)\n",
    "print(f\"Report saved: {md_path}\")\n",
    "\n",
    "print(f\"\\nAll results saved to {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}