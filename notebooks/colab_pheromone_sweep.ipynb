{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pheromone Hyperparameter Sweep\n",
    "\n",
    "## Methodology\n",
    "\n",
    "**One-at-a-time sweep** across 6 parameter groups for the biological pheromone system.\n",
    "Each parameter group is swept independently while holding all others at their base values.\n",
    "3 seeds per value, 23 configs total = **69 training runs**.\n",
    "\n",
    "## Sweep Design\n",
    "\n",
    "| Group | Parameter | Values | Count |\n",
    "|-------|-----------|--------|-------|\n",
    "| 1 | Recruitment decay (`channel_decay_rates[0]`) | 0.02, 0.03, 0.05, 0.08 | 4 |\n",
    "| 2 | Recruitment diffusion (`channel_diffusion_rates[0]`) | 0.2, 0.3, 0.5, 0.7 | 4 |\n",
    "| 3 | Territory write strength (`field.territory_write_strength`) | 0.005, 0.01, 0.02, 0.05 | 4 |\n",
    "| 4 | Compass noise (`nest.compass_noise_rate`) | 0.05, 0.10, 0.15, 0.20 | 4 |\n",
    "| 5 | Scout sip fraction (`nest.food_sip_fraction`) | 0.05, 0.10, 0.15 | 3 |\n",
    "| 6 | Nest radius (`nest.radius`) | 2, 3, 4 | 3 |\n",
    "| baseline | Field OFF (no pheromone) | — | 1 |\n",
    "| **Total** | | | **23 configs × 3 seeds = 69 runs** |\n",
    "\n",
    "## Base Config\n",
    "\n",
    "| Parameter | Value | Rationale |\n",
    "|-----------|-------|-----------|\n",
    "| `grid_size` | 40 | Large arena for trail formation |\n",
    "| `num_agents` | 16 | Starting population |\n",
    "| `num_food` | 25 | More generous (carry-back mechanic makes food harder) |\n",
    "| `food_energy` | 100 | More generous for pheromone system |\n",
    "| `max_agents` | 64 | Population cap |\n",
    "| `total_steps` | 2M | Per-config training budget |\n",
    "| `nest.radius` | 2 | 5×5 nest area (default) |\n",
    "| `channel_diffusion_rates` | (0.5, 0.01, 0.0, 0.0) | Recruitment spreads wide, territory stays local |\n",
    "| `channel_decay_rates` | (0.05, 0.0001, 0.0, 0.0) | Recruitment fades fast, territory near-permanent |\n",
    "\n",
    "## Decision Gates\n",
    "\n",
    "- **After Group 1** (first 5 configs): If ALL runs have population < 5, print warning and suggest bumping `num_food` to 30 or `food_energy` to 120.\n",
    "- **After full sweep**: Auto-select best value per group, combine into best config, run confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Setup\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "REPO_DIR = '/content/emergence-lab'\n",
    "GITHUB_USERNAME = 'imashishkh21'\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/{GITHUB_USERNAME}/emergence-lab.git {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull origin main\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "!pip install -e \".[dev]\" -q\n",
    "!pip install rliable -q\n",
    "\n",
    "# Verify pheromone system support\n",
    "from src.configs import NestConfig, FieldConfig\n",
    "assert hasattr(NestConfig, 'radius'), \"NestConfig missing! Pull latest main.\"\n",
    "assert hasattr(FieldConfig, 'territory_write_strength'), (\n",
    "    \"FieldConfig missing territory_write_strength! Pull latest main.\"\n",
    ")\n",
    "assert hasattr(FieldConfig, 'channel_decay_rates'), (\n",
    "    \"FieldConfig missing channel_decay_rates! Pull latest main.\"\n",
    ")\n",
    "print(f\"NestConfig defaults: radius={NestConfig().radius}, \"\n",
    "      f\"sip={NestConfig().food_sip_fraction}, noise={NestConfig().compass_noise_rate}\")\n",
    "print(f\"FieldConfig territory_write_strength default: {FieldConfig().territory_write_strength}\")\n",
    "\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweep Configuration\n",
    "\n",
    "Each config is built from the base by overriding a single parameter.\n",
    "The field-off baseline disables the field entirely (diffusion=0, decay=1, write_strength=0).\n",
    "\n",
    "**NOTE:** `territory_write_strength` must be a configurable field in `FieldConfig`.\n",
    "If Group 3 fails with `AttributeError`, the pheromone config changes haven't been merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3 — Sweep Configuration\nimport copy\nfrom dataclasses import dataclass\nfrom src.configs import Config, NestConfig, TrainingMode\n\n# --- Constants ---\nNUM_ENVS = 32\nNUM_STEPS = 128\nMAX_AGENTS = 64\nSTEPS_PER_ITER = NUM_ENVS * NUM_STEPS * MAX_AGENTS  # 262,144\nNUM_ITERATIONS = 8   # ~2.1M steps\nTOTAL_STEPS = 2_000_000\n\n\ndef build_config(**overrides) -> Config:\n    \"\"\"Build base pheromone config with optional overrides.\"\"\"\n    cfg = Config()\n\n    # Environment\n    cfg.env.grid_size = 40\n    cfg.env.num_agents = 16\n    cfg.env.num_food = 25\n    cfg.env.max_steps = 500\n    cfg.env.observation_radius = 5\n\n    # Evolution\n    cfg.evolution.enabled = True\n    cfg.evolution.food_energy = 100\n    cfg.evolution.starting_energy = 200\n    cfg.evolution.max_energy = 300\n    cfg.evolution.reproduce_threshold = 180\n    cfg.evolution.reproduce_cost = 80\n    cfg.evolution.energy_per_step = 1\n    cfg.evolution.max_agents = MAX_AGENTS\n    cfg.evolution.mutation_std = 0.01\n\n    # Training\n    cfg.train.training_mode = TrainingMode.GRADIENT\n    cfg.train.num_envs = NUM_ENVS\n    cfg.train.num_steps = NUM_STEPS\n    cfg.train.total_steps = TOTAL_STEPS\n    cfg.log.wandb = False\n    cfg.log.save_interval = 0\n\n    # Nest\n    cfg.nest.radius = 2\n    cfg.nest.food_sip_fraction = 0.05\n    cfg.nest.compass_noise_rate = 0.10\n\n    # Field: per-channel pheromone settings\n    cfg.field.num_channels = 4\n    cfg.field.channel_diffusion_rates = (0.5, 0.01, 0.0, 0.0)\n    cfg.field.channel_decay_rates = (0.05, 0.0001, 0.0, 0.0)\n    cfg.field.field_value_cap = 1.0\n    cfg.field.territory_write_strength = 0.01\n\n    # Hidden food: disabled for pheromone sweep (focus on foraging)\n    cfg.env.hidden_food.enabled = False\n\n    # Apply overrides\n    for key, val in overrides.items():\n        parts = key.split('.')\n        obj = cfg\n        for part in parts[:-1]:\n            obj = getattr(obj, part)\n        setattr(obj, parts[-1], val)\n\n    return cfg\n\n\ndef build_field_off_config() -> Config:\n    \"\"\"Build field-OFF baseline: same base but field disabled.\n\n    Only per-channel rates are set — they override the scalar defaults in env.py.\n    All channels get zero diffusion + instant decay, and territory writes are off.\n    \"\"\"\n    cfg = build_config()\n    cfg.field.channel_diffusion_rates = (0.0, 0.0, 0.0, 0.0)\n    cfg.field.channel_decay_rates = (1.0, 1.0, 1.0, 1.0)\n    cfg.field.territory_write_strength = 0.0\n    return cfg\n\n\n# --- Build all 23 sweep configs ---\n@dataclass\nclass SweepEntry:\n    name: str\n    group: int\n    param_name: str\n    param_value: object\n    config: Config\n\n\nBASE_DECAY_RATES = (0.05, 0.0001, 0.0, 0.0)\nBASE_DIFFUSION_RATES = (0.5, 0.01, 0.0, 0.0)\n\nsweep_configs: list[SweepEntry] = []\n\n# Baseline FIRST so early decision gate can compare against it\nsweep_configs.append(SweepEntry(\n    name='baseline_field_off',\n    group=0,\n    param_name='field_off',\n    param_value=None,\n    config=build_field_off_config(),\n))\n\n# Group 1: Recruitment decay (channel_decay_rates[0])\nfor val in [0.02, 0.03, 0.05, 0.08]:\n    rates = (val,) + BASE_DECAY_RATES[1:]\n    cfg = build_config(**{'field.channel_decay_rates': rates})\n    sweep_configs.append(SweepEntry(\n        name=f'g1_recruit_decay_{val}',\n        group=1,\n        param_name='channel_decay_rates[0]',\n        param_value=val,\n        config=cfg,\n    ))\n\n# Group 2: Recruitment diffusion (channel_diffusion_rates[0])\nfor val in [0.2, 0.3, 0.5, 0.7]:\n    rates = (val,) + BASE_DIFFUSION_RATES[1:]\n    cfg = build_config(**{'field.channel_diffusion_rates': rates})\n    sweep_configs.append(SweepEntry(\n        name=f'g2_recruit_diffusion_{val}',\n        group=2,\n        param_name='channel_diffusion_rates[0]',\n        param_value=val,\n        config=cfg,\n    ))\n\n# Group 3: Territory write strength\nfor val in [0.005, 0.01, 0.02, 0.05]:\n    cfg = build_config(**{'field.territory_write_strength': val})\n    sweep_configs.append(SweepEntry(\n        name=f'g3_territory_write_{val}',\n        group=3,\n        param_name='territory_write_strength',\n        param_value=val,\n        config=cfg,\n    ))\n\n# Group 4: Compass noise\nfor val in [0.05, 0.10, 0.15, 0.20]:\n    cfg = build_config(**{'nest.compass_noise_rate': val})\n    sweep_configs.append(SweepEntry(\n        name=f'g4_compass_noise_{val}',\n        group=4,\n        param_name='compass_noise_rate',\n        param_value=val,\n        config=cfg,\n    ))\n\n# Group 5: Scout sip fraction\nfor val in [0.05, 0.10, 0.15]:\n    cfg = build_config(**{'nest.food_sip_fraction': val})\n    sweep_configs.append(SweepEntry(\n        name=f'g5_sip_fraction_{val}',\n        group=5,\n        param_name='food_sip_fraction',\n        param_value=val,\n        config=cfg,\n    ))\n\n# Group 6: Nest radius\nfor val in [2, 3, 4]:\n    cfg = build_config(**{'nest.radius': val})\n    sweep_configs.append(SweepEntry(\n        name=f'g6_nest_radius_{val}',\n        group=6,\n        param_name='nest_radius',\n        param_value=val,\n        config=cfg,\n    ))\n\nassert len(sweep_configs) == 23, f\"Expected 23 configs, got {len(sweep_configs)}\"\n\n# Print summary\nprint(f\"Total sweep configs: {len(sweep_configs)}\")\nprint(f\"Total runs (3 seeds each): {len(sweep_configs) * 3}\")\nprint(f\"Steps per config: ~{NUM_ITERATIONS * STEPS_PER_ITER:,}\")\nprint()\nprint(f\"{'#':<4} {'Name':<30} {'Group':>5} {'Param':<30} {'Value'}\")\nprint('-' * 85)\nfor i, sc in enumerate(sweep_configs):\n    print(f\"{i:<4} {sc.name:<30} {sc.group:>5} {sc.param_name:<30} {sc.param_value}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Training Phase\n\nTrain all 23 configs, 3 seeds each. Results are saved incrementally to Google Drive.\nResume-safe: re-running skips already-completed configs.\n\n**Config order:** Baseline runs first (index 0), then Group 1–6.\n\n**Early decision gate** after first 5 configs (baseline + Group 1):\nif all runs have population < 5, prints a warning with suggested parameter adjustments."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5 — Training Loop\nimport gc\nimport os\nimport pickle\nimport time\nimport traceback\nfrom datetime import datetime, timedelta\n\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\n\nfrom src.training.parallel_train import ParallelTrainer\nfrom src.agents.network import ActorCritic\nfrom src.agents.policy import sample_actions\nfrom src.environment.env import reset, step\nfrom src.environment.obs import get_observations\n\nDRIVE_BASE = '/content/drive/MyDrive/emergence-lab/pheromone_sweep'\nRESULTS_PATH = f'{DRIVE_BASE}/sweep_results.pkl'\nos.makedirs(DRIVE_BASE, exist_ok=True)\n\nSEEDS_PER_CONFIG = 3\n\n\n# --- Eval function using jax.lax.scan for speed ---\ndef run_eval(network, params, config, key, num_steps=500):\n    \"\"\"Run a single eval episode using lax.scan.\n\n    Follows the collect_rollout pattern in src/training/rollout.py:\n    scan body closes over network, params, config; carry holds\n    (state, key, total_reward); runs for num_steps.\n    \"\"\"\n    key, reset_key = jax.random.split(key)\n    init_state = reset(reset_key, config)\n\n    def _eval_step(carry, _unused):\n        state, rng, total_reward = carry\n        obs = get_observations(state, config)          # (max_agents, obs_dim)\n        obs_batched = obs[None, :, :]                   # (1, max_agents, obs_dim)\n        rng, act_key = jax.random.split(rng)\n        actions, _, _, _ = sample_actions(network, params, obs_batched, act_key)\n        actions = actions[0]                             # (max_agents,)\n        state, rewards, done, info = step(state, actions, config)\n        alive = state.agent_alive.astype(jnp.float32)\n        total_reward = total_reward + jnp.sum(rewards * alive)\n        return (state, rng, total_reward), None\n\n    (final_state, _, total_reward), _ = jax.lax.scan(\n        _eval_step, (init_state, key, jnp.float32(0.0)), None, length=num_steps,\n    )\n\n    # Extract metrics AFTER the scan (not inside)\n    ch0 = jnp.asarray(final_state.field_state.values[:, :, 0])\n    nonzero_mask = ch0 > 0.01\n    trail_strength = jnp.where(\n        jnp.any(nonzero_mask),\n        jnp.sum(jnp.where(nonzero_mask, ch0, 0.0)) / jnp.maximum(jnp.sum(nonzero_mask.astype(jnp.float32)), 1.0),\n        0.0,\n    )\n    final_pop = jnp.sum(final_state.agent_alive.astype(jnp.int32))\n    return {\n        'total_reward': float(total_reward),\n        'final_population': int(final_pop),\n        'trail_strength': float(trail_strength),\n        'survival_rate': float(final_pop) / config.env.num_agents,\n    }\n\n\n# --- Load existing results for resume ---\nif os.path.exists(RESULTS_PATH):\n    with open(RESULTS_PATH, 'rb') as f:\n        all_results = pickle.load(f)\n    print(f\"Resumed: {len(all_results)} configs already completed\")\nelse:\n    all_results = {}\n\n\ndef save_results():\n    \"\"\"Save results dict to Drive (atomic write).\"\"\"\n    tmp_path = RESULTS_PATH + '.tmp'\n    with open(tmp_path, 'wb') as f:\n        pickle.dump(all_results, f, protocol=pickle.HIGHEST_PROTOCOL)\n    os.replace(tmp_path, RESULTS_PATH)\n\n\n# --- Main training loop ---\nsweep_start = time.time()\ntotal_configs = len(sweep_configs)\n\nfor i, sc in enumerate(sweep_configs):\n    # Skip if already completed\n    if sc.name in all_results and all_results[sc.name].get('success'):\n        print(f\"[{i+1}/{total_configs}] {sc.name} - SKIPPED (already done)\")\n        continue\n\n    print(f\"\\n{'='*60}\")\n    print(f\"[{i+1}/{total_configs}] Training: {sc.name} (Group {sc.group})\")\n    print(f\"  {sc.param_name} = {sc.param_value}\")\n    print(f\"{'='*60}\")\n\n    seed_ids = [300 + i * 3, 300 + i * 3 + 1, 300 + i * 3 + 2]\n    checkpoint_dir = f'{DRIVE_BASE}/{sc.name}'\n\n    try:\n        t0 = time.time()\n        trainer = ParallelTrainer(\n            config=sc.config,\n            num_seeds=SEEDS_PER_CONFIG,\n            seed_ids=seed_ids,\n            checkpoint_dir=checkpoint_dir,\n            master_seed=42 + i,\n        )\n        metrics = trainer.train(\n            num_iterations=NUM_ITERATIONS,\n            checkpoint_interval_minutes=999,\n            resume=False,\n            print_interval=2,\n        )\n        train_time = time.time() - t0\n\n        # --- Eval per seed ---\n        num_actions = getattr(sc.config.agent, 'num_actions', 5)\n        ps = trainer._parallel_state\n        network = ActorCritic(\n            hidden_dims=tuple(sc.config.agent.hidden_dims),\n            num_actions=num_actions,\n        )\n\n        seed_evals = []\n        for s in range(SEEDS_PER_CONFIG):\n            seed_params = jax.tree.map(lambda x: x[s], ps.params)\n            eval_key = jax.random.PRNGKey(1000 + seed_ids[s])\n            eval_result = run_eval(network, seed_params, sc.config, eval_key, num_steps=500)\n            seed_evals.append(eval_result)\n\n        # Aggregate across seeds\n        metric_keys = seed_evals[0].keys()\n        agg = {}\n        for k in metric_keys:\n            vals = [e[k] for e in seed_evals]\n            agg[f'{k}_mean'] = float(np.mean(vals))\n            agg[f'{k}_std'] = float(np.std(vals))\n            agg[f'{k}_values'] = vals\n\n        # Population from training state\n        alive = np.array(ps.env_state.agent_alive)  # (num_seeds, num_envs, max_agents)\n        train_pop_per_seed = alive.sum(axis=(1, 2)) / alive.shape[1]\n\n        all_results[sc.name] = {\n            'success': True,\n            'group': sc.group,\n            'param_name': sc.param_name,\n            'param_value': sc.param_value,\n            'train_metrics': metrics,\n            'train_time': train_time,\n            'train_pop_per_seed': [float(p) for p in train_pop_per_seed],\n            'eval_per_seed': seed_evals,\n            'eval_agg': agg,\n        }\n\n        print(f\"  Done in {train_time:.0f}s\")\n        print(f\"  Reward: {agg['total_reward_mean']:.1f} +/- {agg['total_reward_std']:.1f}\")\n        print(f\"  Population: {agg['final_population_mean']:.1f} +/- {agg['final_population_std']:.1f}\")\n        print(f\"  Trail strength: {agg['trail_strength_mean']:.4f}\")\n        print(f\"  Survival rate: {agg['survival_rate_mean']:.2f}\")\n\n    except Exception as e:\n        print(f\"  FAILED: {e}\")\n        traceback.print_exc()\n        all_results[sc.name] = {\n            'success': False,\n            'group': sc.group,\n            'param_name': sc.param_name,\n            'param_value': sc.param_value,\n            'error': str(e),\n        }\n\n    finally:\n        try:\n            del trainer\n        except NameError:\n            pass\n        gc.collect()\n        jax.clear_caches()\n\n    # Save after every config\n    save_results()\n\n    # Progress report\n    completed = sum(1 for r in all_results.values() if r.get('success'))\n    elapsed = time.time() - sweep_start\n    if completed > 0:\n        avg_time = elapsed / completed\n        remaining = avg_time * (total_configs - completed)\n        eta = datetime.now() + timedelta(seconds=remaining)\n        print(f\"  Progress: {completed}/{total_configs} | \"\n              f\"Elapsed: {elapsed/60:.0f}min | ETA: {eta.strftime('%H:%M')}\")\n\n    # --- EARLY DECISION GATE after baseline + Group 1 (first 5 configs) ---\n    # Config order: [0]=baseline, [1-4]=Group 1 decay values\n    if i == 4:\n        print(\"\\n\" + \"=\"*60)\n        print(\"EARLY DECISION GATE (after baseline + Group 1)\")\n        print(\"=\"*60)\n        max_pop = 0\n        for name, r in all_results.items():\n            if r.get('success'):\n                pop = r['eval_agg'].get('final_population_mean', 0)\n                max_pop = max(max_pop, pop)\n                print(f\"  {name}: pop={pop:.1f}, reward={r['eval_agg']['total_reward_mean']:.1f}\")\n        if max_pop < 5:\n            print(\"\\n\\u274c WARNING: All runs have population < 5!\")\n            print(\"  Consider adjusting base params:\")\n            print(\"    - Increase num_food from 25 to 30\")\n            print(\"    - Increase food_energy from 100 to 120\")\n            print(\"    - Decrease energy_per_step from 1 to 0.5\")\n            print(\"  Continuing sweep, but results may be unreliable.\")\n        else:\n            print(f\"\\n\\u2705 PASS: Max population = {max_pop:.1f}. Proceeding.\")\n\ntotal_elapsed = time.time() - sweep_start\ncompleted = sum(1 for r in all_results.values() if r.get('success'))\nprint(f\"\\n{'='*60}\")\nprint(f\"SWEEP COMPLETE: {completed}/{total_configs} successful in {total_elapsed/60:.0f} min\")\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Phase\n",
    "\n",
    "Load results, build comparison tables, generate plots, auto-select best config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 — Load Results & Master Comparison Table\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "DRIVE_BASE = '/content/drive/MyDrive/emergence-lab/pheromone_sweep'\n",
    "RESULTS_PATH = f'{DRIVE_BASE}/sweep_results.pkl'\n",
    "\n",
    "with open(RESULTS_PATH, 'rb') as f:\n",
    "    all_results = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(all_results)} configs\")\n",
    "\n",
    "# Build rows sorted by total_reward\n",
    "rows = []\n",
    "for name, r in all_results.items():\n",
    "    if not r.get('success'):\n",
    "        continue\n",
    "    agg = r['eval_agg']\n",
    "    rows.append({\n",
    "        'name': name,\n",
    "        'group': r['group'],\n",
    "        'param_name': r['param_name'],\n",
    "        'param_value': r['param_value'],\n",
    "        'reward_mean': agg['total_reward_mean'],\n",
    "        'reward_std': agg['total_reward_std'],\n",
    "        'pop_mean': agg['final_population_mean'],\n",
    "        'pop_std': agg['final_population_std'],\n",
    "        'trail_mean': agg['trail_strength_mean'],\n",
    "        'trail_std': agg['trail_strength_std'],\n",
    "        'survival_mean': agg['survival_rate_mean'],\n",
    "        'survival_std': agg['survival_rate_std'],\n",
    "    })\n",
    "\n",
    "rows.sort(key=lambda r: r['reward_mean'], reverse=True)\n",
    "\n",
    "# Print formatted table\n",
    "print(f\"\\n{'Rank':<5} {'Group':>5} {'Config Name':<30} \"\n",
    "      f\"{'Reward':>16} {'Population':>16} {'Trail Str':>14} {'Survival':>12}\")\n",
    "print('-' * 105)\n",
    "for rank, row in enumerate(rows, 1):\n",
    "    print(f\"{rank:<5} {row['group']:>5} {row['name']:<30} \"\n",
    "          f\"{row['reward_mean']:>7.1f}+/-{row['reward_std']:<6.1f} \"\n",
    "          f\"{row['pop_mean']:>7.1f}+/-{row['pop_std']:<6.1f} \"\n",
    "          f\"{row['trail_mean']:>7.4f}+/-{row['trail_std']:<5.4f} \"\n",
    "          f\"{row['survival_mean']:>5.2f}+/-{row['survival_std']:<4.2f}\")\n",
    "\n",
    "# Find baseline for reference\n",
    "baseline_row = next((r for r in rows if r['name'] == 'baseline_field_off'), None)\n",
    "if baseline_row:\n",
    "    print(f\"\\nBaseline (field OFF): reward={baseline_row['reward_mean']:.1f}, \"\n",
    "          f\"pop={baseline_row['pop_mean']:.1f}\")\n",
    "\n",
    "n_failed = sum(1 for r in all_results.values() if not r.get('success'))\n",
    "if n_failed > 0:\n",
    "    print(f\"\\n{n_failed} configs FAILED:\")\n",
    "    for name, r in all_results.items():\n",
    "        if not r.get('success'):\n",
    "            print(f\"  {name}: {r.get('error', 'unknown')[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 8 — Plots\nimport matplotlib.pyplot as plt\nimport os\n\nFIGURE_DIR = f'{DRIVE_BASE}/figures'\nos.makedirs(FIGURE_DIR, exist_ok=True)\n\nGROUP_LABELS = {\n    1: 'Recruitment Decay',\n    2: 'Recruitment Diffusion',\n    3: 'Territory Write Strength',\n    4: 'Compass Noise',\n    5: 'Scout Sip Fraction',\n    6: 'Nest Radius',\n}\n\nGROUP_COLORS = {\n    1: '#EE7733',\n    2: '#0077BB',\n    3: '#33BBEE',\n    4: '#EE3377',\n    5: '#009988',\n    6: '#CC3311',\n}\n\n# Baseline reward line\nbaseline_reward = baseline_row['reward_mean'] if baseline_row else 0.0\n\n# --- Figure 1: Grouped bar charts, one subplot per parameter group ---\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes_flat = axes.flatten()\n\nfor idx, group_id in enumerate([1, 2, 3, 4, 5, 6]):\n    ax = axes_flat[idx]\n    group_rows = [r for r in rows if r['group'] == group_id]\n    group_rows.sort(key=lambda r: float(r['param_value']))\n\n    x_labels = [str(r['param_value']) for r in group_rows]\n    x_pos = np.arange(len(group_rows))\n    means = [r['reward_mean'] for r in group_rows]\n    stds = [r['reward_std'] for r in group_rows]\n\n    ax.bar(x_pos, means, yerr=stds, color=GROUP_COLORS[group_id],\n           edgecolor='black', linewidth=0.8, capsize=4, alpha=0.85)\n    ax.axhline(y=baseline_reward, color='gray', linestyle='--', linewidth=1.5,\n               label=f'Field OFF ({baseline_reward:.0f})')\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels(x_labels)\n    ax.set_xlabel(group_rows[0]['param_name'] if group_rows else '')\n    ax.set_ylabel('Total Reward (mean +/- std)')\n    ax.set_title(f'Group {group_id}: {GROUP_LABELS[group_id]}')\n    ax.legend(fontsize=8)\n\nfig.suptitle('Pheromone Sweep: Reward by Parameter Group', fontsize=16, y=1.02)\nfig.tight_layout()\nfig.savefig(os.path.join(FIGURE_DIR, 'grouped_bars.png'), dpi=300, bbox_inches='tight')\nplt.show()\n\n# --- Figure 2: Heatmap of all 23 configs x 4 metrics ---\nmetric_keys = ['reward_mean', 'pop_mean', 'trail_mean', 'survival_mean']\nmetric_labels = ['Total Reward', 'Population', 'Trail Strength', 'Survival Rate']\n\n# Sort rows by group then param_value\nheatmap_rows = sorted(rows, key=lambda r: (r['group'], str(r['param_value'])))\nn_configs = len(heatmap_rows)\nn_metrics = len(metric_keys)\n\nheatmap_data = np.zeros((n_configs, n_metrics))\nfor i, row in enumerate(heatmap_rows):\n    for j, mk in enumerate(metric_keys):\n        heatmap_data[i, j] = row[mk]\n\n# Normalize per column (min-max)\nheatmap_norm = np.zeros_like(heatmap_data)\nfor j in range(n_metrics):\n    col = heatmap_data[:, j]\n    cmin, cmax = col.min(), col.max()\n    if cmax > cmin:\n        heatmap_norm[:, j] = (col - cmin) / (cmax - cmin)\n    else:\n        heatmap_norm[:, j] = 0.5\n\nfig2, ax2 = plt.subplots(figsize=(10, max(8, n_configs * 0.4)))\nim = ax2.imshow(heatmap_norm, aspect='auto', cmap='YlOrRd')\nax2.set_xticks(range(n_metrics))\nax2.set_xticklabels(metric_labels, rotation=30, ha='right')\nax2.set_yticks(range(n_configs))\nax2.set_yticklabels([f\"G{r['group']} {r['name']}\" for r in heatmap_rows], fontsize=7)\n# Annotate cells with raw values\nfor i in range(n_configs):\n    for j in range(n_metrics):\n        val = heatmap_data[i, j]\n        fmt = '.0f' if j < 2 else '.3f' if j == 2 else '.2f'\n        ax2.text(j, i, f\"{val:{fmt}}\", ha='center', va='center', fontsize=6,\n                 color='white' if heatmap_norm[i, j] > 0.6 else 'black')\nfig2.colorbar(im, ax=ax2, label='Normalized (per column)', shrink=0.8)\nax2.set_title('Pheromone Sweep: All Configs x Metrics Heatmap')\nfig2.tight_layout()\nfig2.savefig(os.path.join(FIGURE_DIR, 'heatmap.png'), dpi=300, bbox_inches='tight')\nplt.show()\n\n# --- Figure 3: Best-of-each-group summary bar chart ---\nbest_per_group = {}\nfor row in rows:\n    g = row['group']\n    if g == 0:\n        continue  # skip baseline\n    if g not in best_per_group or row['reward_mean'] > best_per_group[g]['reward_mean']:\n        best_per_group[g] = row\n\nfig3, ax3 = plt.subplots(figsize=(10, 5))\nlabels = []\nmeans = []\nstds = []\ncolors = []\nfor g in sorted(best_per_group.keys()):\n    r = best_per_group[g]\n    labels.append(f\"G{g}: {r['param_name']}={r['param_value']}\")\n    means.append(r['reward_mean'])\n    stds.append(r['reward_std'])\n    colors.append(GROUP_COLORS.get(g, '#999999'))\n\n# Add baseline\nif baseline_row:\n    labels.append('Baseline (Field OFF)')\n    means.append(baseline_row['reward_mean'])\n    stds.append(baseline_row['reward_std'])\n    colors.append('#BBBBBB')\n\nx_pos = np.arange(len(labels))\nax3.barh(x_pos, means, xerr=stds, color=colors, edgecolor='black', linewidth=0.8, capsize=4)\nax3.set_yticks(x_pos)\nax3.set_yticklabels(labels, fontsize=9)\nax3.set_xlabel('Total Reward (mean +/- std)')\nax3.set_title('Best Value Per Parameter Group vs Baseline')\nax3.invert_yaxis()\nfig3.tight_layout()\nfig3.savefig(os.path.join(FIGURE_DIR, 'best_per_group.png'), dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"Figures saved to {FIGURE_DIR}/\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 — Auto-select Best Per Group + Save Combined Config\n",
    "import yaml\n",
    "\n",
    "print(\"Best parameter value per group (by mean total_reward):\")\n",
    "print(f\"{'Group':>5} {'Parameter':<30} {'Best Value':>12} {'Reward':>12}\")\n",
    "print('-' * 65)\n",
    "\n",
    "best_values = {}  # group -> (param_name, best_value, reward)\n",
    "for g in sorted(best_per_group.keys()):\n",
    "    r = best_per_group[g]\n",
    "    best_values[g] = (r['param_name'], r['param_value'], r['reward_mean'])\n",
    "    print(f\"{g:>5} {r['param_name']:<30} {str(r['param_value']):>12} {r['reward_mean']:>12.1f}\")\n",
    "\n",
    "# Build combined best config\n",
    "best_overrides = {}\n",
    "for g, (param_name, param_value, _) in best_values.items():\n",
    "    if g == 1:\n",
    "        base_rates = list(build_config().field.channel_decay_rates)\n",
    "        base_rates[0] = param_value\n",
    "        best_overrides['field.channel_decay_rates'] = tuple(base_rates)\n",
    "    elif g == 2:\n",
    "        base_rates = list(build_config().field.channel_diffusion_rates)\n",
    "        base_rates[0] = param_value\n",
    "        best_overrides['field.channel_diffusion_rates'] = tuple(base_rates)\n",
    "    elif g == 3:\n",
    "        best_overrides['field.territory_write_strength'] = param_value\n",
    "    elif g == 4:\n",
    "        best_overrides['nest.compass_noise_rate'] = param_value\n",
    "    elif g == 5:\n",
    "        best_overrides['nest.food_sip_fraction'] = param_value\n",
    "    elif g == 6:\n",
    "        best_overrides['nest.radius'] = param_value\n",
    "\n",
    "best_config = build_config(**best_overrides)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDED COMBINED CONFIG\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  channel_decay_rates:     {best_config.field.channel_decay_rates}\")\n",
    "print(f\"  channel_diffusion_rates: {best_config.field.channel_diffusion_rates}\")\n",
    "print(f\"  territory_write_strength: {best_config.field.territory_write_strength}\")\n",
    "print(f\"  compass_noise_rate:       {best_config.nest.compass_noise_rate}\")\n",
    "print(f\"  food_sip_fraction:        {best_config.nest.food_sip_fraction}\")\n",
    "print(f\"  nest_radius:              {best_config.nest.radius}\")\n",
    "\n",
    "# Save as YAML\n",
    "yaml_path = '/content/drive/MyDrive/emergence-lab/pheromone_best_config.yaml'\n",
    "best_config.to_yaml(yaml_path)\n",
    "print(f\"\\nSaved best config to {yaml_path}\")\n",
    "\n",
    "# Also print as copy-paste Python for convenience\n",
    "print(\"\\n# Copy-paste config for full training notebook:\")\n",
    "print(f\"cfg.field.channel_decay_rates = {best_config.field.channel_decay_rates}\")\n",
    "print(f\"cfg.field.channel_diffusion_rates = {best_config.field.channel_diffusion_rates}\")\n",
    "print(f\"cfg.field.territory_write_strength = {best_config.field.territory_write_strength}\")\n",
    "print(f\"cfg.nest.compass_noise_rate = {best_config.nest.compass_noise_rate}\")\n",
    "print(f\"cfg.nest.food_sip_fraction = {best_config.nest.food_sip_fraction}\")\n",
    "print(f\"cfg.nest.radius = {best_config.nest.radius}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 10 — Confirmation Run: Best Combined vs Default vs Field-OFF\nimport gc\nimport time\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\nfrom src.training.parallel_train import ParallelTrainer\nfrom src.agents.network import ActorCritic\n\nCONFIRM_ITERS = NUM_ITERATIONS  # Same as sweep: ~2M steps\nCONFIRM_SEEDS = 3\n\nconfirm_configs = {\n    'best_combined': best_config,\n    'default_base': build_config(),   # All defaults\n}\n\nconfirm_results = {}\n\n# Reuse field-off baseline from sweep if available\nif 'baseline_field_off' in all_results and all_results['baseline_field_off'].get('success'):\n    confirm_results['field_off'] = all_results['baseline_field_off']['eval_agg']\n    print(\"Reusing field-off baseline from sweep.\")\nelse:\n    confirm_configs['field_off'] = build_field_off_config()\n\nfor cond_name, cfg in confirm_configs.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"Confirmation: {cond_name}\")\n    print(f\"{'='*60}\")\n\n    seed_ids = [900, 901, 902]\n    checkpoint_dir = f'{DRIVE_BASE}/confirm_{cond_name}'\n\n    try:\n        t0 = time.time()\n        trainer = ParallelTrainer(\n            config=cfg,\n            num_seeds=CONFIRM_SEEDS,\n            seed_ids=seed_ids,\n            checkpoint_dir=checkpoint_dir,\n            master_seed=999,\n        )\n        metrics = trainer.train(\n            num_iterations=CONFIRM_ITERS,\n            checkpoint_interval_minutes=999,\n            resume=False,\n            print_interval=2,\n        )\n        train_time = time.time() - t0\n\n        # Eval\n        num_actions = getattr(cfg.agent, 'num_actions', 5)\n        ps = trainer._parallel_state\n        network = ActorCritic(\n            hidden_dims=tuple(cfg.agent.hidden_dims),\n            num_actions=num_actions,\n        )\n        seed_evals = []\n        for s in range(CONFIRM_SEEDS):\n            seed_params = jax.tree.map(lambda x: x[s], ps.params)\n            eval_key = jax.random.PRNGKey(2000 + seed_ids[s])\n            eval_result = run_eval(network, seed_params, cfg, eval_key, num_steps=500)\n            seed_evals.append(eval_result)\n\n        metric_keys = seed_evals[0].keys()\n        agg = {}\n        for k in metric_keys:\n            vals = [e[k] for e in seed_evals]\n            agg[f'{k}_mean'] = float(np.mean(vals))\n            agg[f'{k}_std'] = float(np.std(vals))\n\n        confirm_results[cond_name] = agg\n        print(f\"  Done in {train_time:.0f}s\")\n        print(f\"  Reward: {agg['total_reward_mean']:.1f} +/- {agg['total_reward_std']:.1f}\")\n        print(f\"  Population: {agg['final_population_mean']:.1f}\")\n\n    except Exception as e:\n        print(f\"  FAILED: {e}\")\n        import traceback; traceback.print_exc()\n        confirm_results[cond_name] = {'error': str(e)}\n\n    finally:\n        try:\n            del trainer\n        except NameError:\n            pass\n        gc.collect()\n        jax.clear_caches()\n\n# --- Comparison Table ---\nprint(\"\\n\" + \"=\"*70)\nprint(\"CONFIRMATION COMPARISON\")\nprint(\"=\"*70)\nprint(f\"{'Condition':<20} {'Reward':>16} {'Population':>16} {'Trail':>14} {'Survival':>12}\")\nprint('-' * 82)\n\nfor cond_name in ['best_combined', 'default_base', 'field_off']:\n    agg = confirm_results.get(cond_name, {})\n    if 'error' in agg:\n        print(f\"{cond_name:<20} FAILED\")\n        continue\n    print(f\"{cond_name:<20} \"\n          f\"{agg.get('total_reward_mean', 0):>7.1f}+/-{agg.get('total_reward_std', 0):<6.1f} \"\n          f\"{agg.get('final_population_mean', 0):>7.1f}+/-{agg.get('final_population_std', 0):<6.1f} \"\n          f\"{agg.get('trail_strength_mean', 0):>7.4f}+/-{agg.get('trail_strength_std', 0):<5.4f} \"\n          f\"{agg.get('survival_rate_mean', 0):>5.2f}+/-{agg.get('survival_rate_std', 0):<4.2f}\")\n\n# Save confirmation results\nconfirm_path = f'{DRIVE_BASE}/confirmation_results.pkl'\nwith open(confirm_path, 'wb') as f:\n    pickle.dump(confirm_results, f)\nprint(f\"\\nConfirmation results saved to {confirm_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report\n",
    "\n",
    "### Winning Configuration\n",
    "\n",
    "The best value for each parameter group was selected by highest mean total reward across 3 seeds.\n",
    "These values were combined into a single \"best\" config and validated in a confirmation run\n",
    "against the default base config and field-off baseline.\n",
    "\n",
    "### How to Use\n",
    "\n",
    "The best config has been saved as YAML to:\n",
    "```\n",
    "/content/drive/MyDrive/emergence-lab/pheromone_best_config.yaml\n",
    "```\n",
    "\n",
    "Load it in a full training notebook:\n",
    "```python\n",
    "from src.configs import Config\n",
    "config = Config.from_yaml('/content/drive/MyDrive/emergence-lab/pheromone_best_config.yaml')\n",
    "config.train.total_steps = 10_000_000  # Full 10M step run\n",
    "```\n",
    "\n",
    "### Recommended Next Steps\n",
    "\n",
    "1. **If pheromone > field-off**: Run full 10M steps with best config, 15 seeds\n",
    "2. **If pheromone ~ field-off**: Check trail_strength — if trails form but don't help, the observation/action space may need tuning\n",
    "3. **If pheromone < field-off**: The pheromone system implementation may need debugging; check that carry-back mechanics are working\n",
    "\n",
    "### Sweep Results Location\n",
    "\n",
    "All results are saved to Google Drive:\n",
    "- `pheromone_sweep/sweep_results.pkl` — full results dict\n",
    "- `pheromone_sweep/figures/` — publication-quality plots (300 DPI)\n",
    "- `pheromone_best_config.yaml` — best combined config"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}