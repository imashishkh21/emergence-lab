{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Emergence Lab - Parallel Multi-Seed Training on TPU\n\nThis notebook runs **5 seeds in parallel** on Google Colab TPU.\n\n**Goal**: Run 30 seeds Field ON + 30 seeds Field OFF = 60 total runs for statistical significance.\n\n## Quick Start\n\n| Step | What to do | Time |\n|------|------------|------|\n| **0** | **Run TEST MODE first** (cell after setup) | ~2 min |\n| 1 | If test passes, set `TEST_MODE = False`, then `BATCH_NUMBER = 0` | ~14 min |\n| 2 | Change `BATCH_NUMBER = 1`, run again | ~14 min |\n| ... | Continue batches 2-5 | ... |\n| 7 | Set `FIELD_ENABLED = False`, `BATCH_NUMBER = 0` | ~14 min |\n| ... | Continue batches 1-5 | ... |\n\n**Total time**: ~3 hours for all 60 seeds (after test passes).\n\n## Setup Instructions\n\n1. Open this notebook in Google Colab\n2. Runtime > Change runtime type > **TPU v5e** (or v6e)\n3. Run setup cells (1-4)\n4. **Run TEST MODE cell first** - verify it passes before full training\n5. Then run full training cells"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup\n",
    "\n",
    "Mount Google Drive, clone the repo, and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory\n",
    "import os\n",
    "CHECKPOINT_BASE = '/content/drive/MyDrive/emergence-lab'\n",
    "os.makedirs(CHECKPOINT_BASE, exist_ok=True)\n",
    "print(f\"Checkpoint base: {CHECKPOINT_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repo if not already present\nREPO_DIR = '/content/emergence-lab'\n\n# âš ï¸ CHANGE THIS to your GitHub username\nGITHUB_USERNAME = \"imashishkh\"\n\nif not os.path.exists(REPO_DIR):\n    !git clone https://github.com/{GITHUB_USERNAME}/emergence-lab.git {REPO_DIR}\nelse:\n    print(f\"Repo already exists at {REPO_DIR}\")\n    # Pull latest changes\n    !cd {REPO_DIR} && git pull\n\n# Change to repo directory\nos.chdir(REPO_DIR)\nprint(f\"Working directory: {os.getcwd()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -e \".[dev]\" -q\n",
    "\n",
    "# Verify JAX sees TPU\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")\n",
    "print(f\"Device count: {jax.device_count()}\")\n",
    "\n",
    "# Check if TPU is available\n",
    "if 'tpu' in str(jax.devices()[0]).lower():\n",
    "    print(\"TPU detected!\")\n",
    "else:\n",
    "    print(\"WARNING: TPU not detected. Training will be slower on GPU/CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## âš ï¸ TEST MODE - Run This First!\n\nBefore running the full experiment, do a quick test to verify everything works.\nThis uses ~1% of compute and catches errors early.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# ðŸ§ª TEST RUN - Verify parallel training works before full experiment\n# =============================================================================\n# This runs 2 seeds for 100K steps (~1-2 minutes) to catch errors early.\n# If this succeeds, the full experiment should work.\n\nTEST_MODE = True  # Set to False to skip test and go straight to full training\n\nif TEST_MODE:\n    print(\"=\"*60)\n    print(\"ðŸ§ª TEST MODE: Running quick verification...\")\n    print(\"=\"*60)\n    \n    from src.configs import Config\n    from src.training.parallel_train import ParallelTrainer\n    import time\n    \n    # Minimal test config\n    test_config = Config()\n    test_config.env.num_food = 20\n    test_config.evolution.enabled = True\n    test_config.evolution.max_agents = 32\n    test_config.evolution.starting_energy = 200\n    test_config.evolution.food_energy = 100\n    test_config.evolution.reproduce_threshold = 120\n    test_config.evolution.reproduce_cost = 50\n    test_config.train.num_envs = 32\n    test_config.train.num_steps = 128\n    test_config.log.wandb = False\n    \n    # Test parameters: 2 seeds, 100K steps\n    TEST_STEPS = 100_000\n    TEST_SEEDS = 2\n    TEST_CHECKPOINT_DIR = f'{CHECKPOINT_BASE}/test_run'\n    \n    steps_per_iter = 32 * 128 * 32  # num_envs * num_steps * max_agents\n    test_iterations = TEST_STEPS // steps_per_iter\n    \n    print(f\"Test config:\")\n    print(f\"  Seeds: {TEST_SEEDS}\")\n    print(f\"  Steps: {TEST_STEPS:,}\")\n    print(f\"  Iterations: {test_iterations}\")\n    print(f\"  Checkpoint dir: {TEST_CHECKPOINT_DIR}\")\n    print()\n    \n    # Run test\n    try:\n        test_trainer = ParallelTrainer(\n            config=test_config,\n            num_seeds=TEST_SEEDS,\n            seed_ids=[100, 101],  # Use different IDs to avoid conflicts\n            checkpoint_dir=TEST_CHECKPOINT_DIR,\n            master_seed=9999,\n        )\n        \n        t0 = time.time()\n        test_metrics = test_trainer.train(\n            num_iterations=test_iterations,\n            checkpoint_interval_minutes=60,  # Won't trigger in short test\n            resume=False,\n            print_interval=5,\n        )\n        elapsed = time.time() - t0\n        \n        print()\n        print(\"=\"*60)\n        print(\"âœ… TEST PASSED!\")\n        print(\"=\"*60)\n        print(f\"Time: {elapsed:.1f}s\")\n        print(f\"Final reward: {test_metrics.get('mean_reward', ['N/A'])}\")\n        print()\n        print(\"The parallel training code works. You can now run the full experiment.\")\n        print(\"Set TEST_MODE = False in this cell and run the cells below.\")\n        print(\"=\"*60)\n        \n    except Exception as e:\n        print()\n        print(\"=\"*60)\n        print(\"âŒ TEST FAILED!\")\n        print(\"=\"*60)\n        print(f\"Error: {e}\")\n        print()\n        print(\"DO NOT proceed with full training until this is fixed.\")\n        print(\"Share the error message to debug.\")\n        print(\"=\"*60)\n        raise e\n\nelse:\n    print(\"TEST_MODE = False, skipping test.\")\n    print(\"Proceeding to full training configuration...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration\n",
    "\n",
    "Configure which seeds to run and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION - Edit these values as needed\n# =============================================================================\n\n# Which batch of seeds to run (0-5 for 30 total seeds)\n# Batch 0: seeds 0-4\n# Batch 1: seeds 5-9\n# Batch 2: seeds 10-14\n# Batch 3: seeds 15-19\n# Batch 4: seeds 20-24\n# Batch 5: seeds 25-29\nBATCH_NUMBER = 0  # Change this for each Colab session\n\n# Seeds per batch (5 fits comfortably in 16GB TPU memory)\nSEEDS_PER_BATCH = 5\n\n# Compute seed IDs for this batch\nSEED_IDS = list(range(BATCH_NUMBER * SEEDS_PER_BATCH, (BATCH_NUMBER + 1) * SEEDS_PER_BATCH))\n\n# Training parameters\nTOTAL_STEPS = 10_000_000  # Total environment steps per seed\nNUM_ENVS = 32  # Parallel environments per seed\nNUM_STEPS = 128  # Steps per rollout\n\n# Field ablation setting\n# Set to True for normal training, False for ablation (no field)\nFIELD_ENABLED = True\n\n# Checkpoint directory - SEPARATE for field_on vs field_off\nCONDITION_NAME = \"field_on\" if FIELD_ENABLED else \"field_off\"\nCHECKPOINT_DIR = f'{CHECKPOINT_BASE}/{CONDITION_NAME}/batch_{BATCH_NUMBER}'\n\n# Checkpoint interval in minutes\nCHECKPOINT_INTERVAL_MINUTES = 30\n\n# Resume from existing checkpoints?\nRESUME = True\n\n# =============================================================================\n# Print configuration summary\n# =============================================================================\nprint(\"=\"*60)\nprint(\"Configuration Summary\")\nprint(\"=\"*60)\nprint(f\"Condition: {CONDITION_NAME}\")\nprint(f\"Batch number: {BATCH_NUMBER}\")\nprint(f\"Seed IDs: {SEED_IDS}\")\nprint(f\"Total steps per seed: {TOTAL_STEPS:,}\")\nprint(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\nprint(f\"Checkpoint interval: {CHECKPOINT_INTERVAL_MINUTES} minutes\")\nprint(f\"Field enabled: {FIELD_ENABLED}\")\nprint(f\"Resume from checkpoints: {RESUME}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build configuration\nfrom src.configs import Config, EnvConfig, EvolutionConfig, FieldConfig\n\n# Start with default config\nconfig = Config()\n\n# =============================================================================\n# SURVIVAL-FRIENDLY PARAMETERS (proven to work in overnight runs)\n# Without these, agents die off and training fails!\n# =============================================================================\nconfig.env.num_food = 20              # More food (default 10)\nconfig.evolution.enabled = True\nconfig.evolution.max_agents = 32      # Population cap\nconfig.evolution.starting_energy = 200  # More starting energy (default 100)\nconfig.evolution.food_energy = 100    # More energy per food (default 50)\nconfig.evolution.energy_per_step = 1  # Energy drain per step\nconfig.evolution.reproduce_threshold = 120  # Easier to reproduce (default 150)\nconfig.evolution.reproduce_cost = 50  # Cheaper reproduction (default 80)\nconfig.evolution.mutation_std = 0.01  # Standard mutation rate\n\n# Training parameters\nconfig.train.total_steps = TOTAL_STEPS\nconfig.train.num_envs = NUM_ENVS\nconfig.train.num_steps = NUM_STEPS\nconfig.train.seed = 42  # Master seed (individual seeds are derived)\n\n# Field ablation (if disabled, zero out the field)\nif not FIELD_ENABLED:\n    # Zero out field by setting decay to 1.0 (field becomes zero before observation)\n    config.field.decay_rate = 1.0\n    config.field.diffusion_rate = 0.0\n    config.field.write_strength = 0.0\n\n# Logging (disable W&B for parallel training)\nconfig.log.wandb = False\nconfig.log.save_interval = 0  # We handle checkpointing ourselves\n\nprint(\"Configuration loaded:\")\nprint(f\"  Grid size: {config.env.grid_size}\")\nprint(f\"  Num food: {config.env.num_food}\")\nprint(f\"  Max agents: {config.evolution.max_agents}\")\nprint(f\"  Starting energy: {config.evolution.starting_energy}\")\nprint(f\"  Food energy: {config.evolution.food_energy}\")\nprint(f\"  Reproduce threshold: {config.evolution.reproduce_threshold}\")\nprint(f\"  Field channels: {config.field.num_channels}\")\nprint(f\"  Field enabled: {FIELD_ENABLED}\")\nprint(f\"  Evolution enabled: {config.evolution.enabled}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Training\n",
    "\n",
    "Run parallel training with automatic checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.parallel_train import ParallelTrainer\n",
    "\n",
    "# Calculate number of iterations\n",
    "steps_per_iter = NUM_ENVS * NUM_STEPS * config.evolution.max_agents\n",
    "num_iterations = TOTAL_STEPS // steps_per_iter\n",
    "\n",
    "print(f\"Steps per iteration: {steps_per_iter:,}\")\n",
    "print(f\"Number of iterations: {num_iterations:,}\")\n",
    "print()\n",
    "\n",
    "# Create trainer\n",
    "trainer = ParallelTrainer(\n",
    "    config=config,\n",
    "    num_seeds=SEEDS_PER_BATCH,\n",
    "    seed_ids=SEED_IDS,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    master_seed=42 + BATCH_NUMBER * 1000,  # Different master seed per batch\n",
    ")\n",
    "\n",
    "# Run training\n",
    "metrics = trainer.train(\n",
    "    num_iterations=num_iterations,\n",
    "    checkpoint_interval_minutes=CHECKPOINT_INTERVAL_MINUTES,\n",
    "    resume=RESUME,\n",
    "    print_interval=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final metrics summary\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Metrics Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric_name, values in metrics.items():\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    print(f\"{metric_name}:\")\n",
    "    print(f\"  Mean: {mean:.4f} +/- {std:.4f}\")\n",
    "    print(f\"  Per-seed: {[f'{v:.4f}' for v in values]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Verify Checkpoints\n",
    "\n",
    "List saved checkpoints and print summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "print(\"Saved Checkpoints:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for seed_id in SEED_IDS:\n",
    "    seed_dir = os.path.join(CHECKPOINT_DIR, f\"seed_{seed_id}\")\n",
    "    checkpoints = sorted(glob.glob(os.path.join(seed_dir, \"step_*.pkl\")))\n",
    "    \n",
    "    print(f\"\\nSeed {seed_id}:\")\n",
    "    if checkpoints:\n",
    "        for ckpt in checkpoints[-3:]:  # Show last 3\n",
    "            size_mb = os.path.getsize(ckpt) / (1024 * 1024)\n",
    "            print(f\"  {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Load latest and show step\n",
    "        latest = os.path.join(seed_dir, \"latest.pkl\")\n",
    "        if os.path.exists(latest):\n",
    "            with open(latest, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            print(f\"  Latest step: {data.get('step', 'unknown')}\")\n",
    "    else:\n",
    "        print(\"  No checkpoints found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Checkpoint verification complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary of all batches (run this to see overall progress)\nprint(\"Overall Progress Across All Conditions:\")\nprint(\"=\"*60)\n\nfor condition in [\"field_on\", \"field_off\"]:\n    print(f\"\\n{condition.upper()}:\")\n    print(\"-\"*40)\n    \n    condition_complete = 0\n    condition_expected = 30\n    \n    for batch in range(6):\n        batch_dir = os.path.join(CHECKPOINT_BASE, condition, f\"batch_{batch}\")\n        if os.path.exists(batch_dir):\n            batch_seeds = list(range(batch * 5, (batch + 1) * 5))\n            complete = 0\n            for seed_id in batch_seeds:\n                seed_dir = os.path.join(batch_dir, f\"seed_{seed_id}\")\n                latest = os.path.join(seed_dir, \"latest.pkl\")\n                if os.path.exists(latest):\n                    try:\n                        with open(latest, \"rb\") as f:\n                            data = pickle.load(f)\n                        step = data.get('step', 0)\n                        if step >= TOTAL_STEPS * 0.99:  # 99% complete\n                            complete += 1\n                            condition_complete += 1\n                    except:\n                        pass\n            print(f\"  Batch {batch} (seeds {batch*5}-{batch*5+4}): {complete}/5 complete\")\n        else:\n            print(f\"  Batch {batch} (seeds {batch*5}-{batch*5+4}): Not started\")\n    \n    print(f\"  â†’ {condition} total: {condition_complete}/{condition_expected} seeds\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Once both conditions have 30 seeds, run the report generator:\")\nprint(\"python scripts/generate_multi_seed_report.py \\\\\")\nprint(f\"    --checkpoint-dir {CHECKPOINT_BASE}/field_on \\\\\")\nprint(f\"    --compare-dir {CHECKPOINT_BASE}/field_off\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\n### Running the Full Experiment (60 seeds total)\n\n**Phase 1: Field ON (30 seeds)**\n1. Set `FIELD_ENABLED = True` and `BATCH_NUMBER = 0`, run notebook\n2. Change `BATCH_NUMBER = 1`, run again\n3. Repeat for batches 2, 3, 4, 5\n4. Total time: ~6 Ã— 14 min = ~1.5 hours\n\n**Phase 2: Field OFF (30 seeds)**\n1. Set `FIELD_ENABLED = False` and `BATCH_NUMBER = 0`, run notebook\n2. Change `BATCH_NUMBER = 1`, run again\n3. Repeat for batches 2, 3, 4, 5\n4. Total time: ~6 Ã— 14 min = ~1.5 hours\n\n**Phase 3: Generate Report**\n```bash\npython scripts/generate_multi_seed_report.py \\\n    --checkpoint-dir /path/to/field_on \\\n    --compare-dir /path/to/field_off \\\n    --output-dir reports/multi_seed\n```\n\n### Directory Structure\n```\nemergence-lab/\nâ”œâ”€â”€ field_on/\nâ”‚   â”œâ”€â”€ batch_0/seed_0/, seed_1/, ... seed_4/\nâ”‚   â”œâ”€â”€ batch_1/seed_5/, ... seed_9/\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ field_off/\n    â”œâ”€â”€ batch_0/seed_0/, ... seed_4/\n    â””â”€â”€ ...\n```"
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "emergence_lab_parallel_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}