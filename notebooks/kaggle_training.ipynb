{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emergence Lab - Kaggle Training\n",
    "\n",
    "Autonomous training notebook for running emergence experiments on Kaggle GPUs.\n",
    "\n",
    "**What this does:**\n",
    "1. Installs JAX with CUDA support and verifies GPU access\n",
    "2. Clones the repo and installs dependencies\n",
    "3. Configures hyperparameters\n",
    "4. Resumes from checkpoint if available, otherwise starts fresh\n",
    "5. Runs training with progress display and periodic checkpointing\n",
    "\n",
    "**Usage:**\n",
    "- Upload to Kaggle as a new notebook\n",
    "- Enable GPU accelerator (Settings > Accelerator > GPU T4 x2 or P100)\n",
    "- Run all cells\n",
    "- Checkpoints are saved to `/kaggle/working/checkpoints/`\n",
    "- Download checkpoints after the run completes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install JAX with CUDA and Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Install JAX with CUDA and verify GPU\nimport subprocess\nimport sys\n\n# Install JAX with CUDA 12 support (Kaggle provides CUDA 12.x)\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"jax[cuda12]\",\n])\n\n# Verify GPU is available\nimport jax\nprint(f\"JAX version: {jax.__version__}\")\ndevices = jax.devices()\nprint(f\"Devices: {devices}\")\n\ngpu_devices = [d for d in devices if \"cuda\" in str(d).lower() or \"gpu\" in str(d).lower()]\nif gpu_devices:\n    print(f\"GPU available: {len(gpu_devices)} device(s) - {gpu_devices}\")\nelse:\n    print(\"WARNING: No GPU found! Training will be slow on CPU.\")\n    print(\"Make sure GPU accelerator is enabled in Kaggle notebook settings.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Clone Repo and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Clone repo and install dependencies\nimport os\nimport subprocess\nimport sys\n\nREPO_URL = \"https://github.com/imashishkh21/emergence-lab.git\"\nREPO_DIR = \"/kaggle/working/emergence-lab\"\nBRANCH = \"main\"\n\n# Clone or update repo\nif os.path.exists(REPO_DIR):\n    print(f\"Repo exists at {REPO_DIR}, pulling latest...\")\n    subprocess.check_call([\"git\", \"-C\", REPO_DIR, \"pull\", \"origin\", BRANCH])\nelse:\n    print(f\"Cloning repo to {REPO_DIR}...\")\n    subprocess.check_call([\n        \"git\", \"clone\", \"--branch\", BRANCH, \"--depth\", \"1\", REPO_URL, REPO_DIR,\n    ])\n\n# Install the package (skip JAX since we installed CUDA version above)\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"-e\", REPO_DIR,\n    \"--no-deps\",  # Skip deps to avoid overwriting CUDA JAX\n])\n\n# Install non-JAX dependencies separately\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"flax>=0.8.0\", \"optax>=0.1.7\", \"chex>=0.1.8\",\n    \"numpy>=1.24.0\", \"scipy>=1.10.0\", \"scikit-learn>=1.3.0\",\n    \"pyyaml>=6.0\", \"tqdm>=4.65.0\", \"matplotlib>=3.7.0\",\n    \"wandb>=0.16.0\", \"imageio>=2.31.0\", \"imageio-ffmpeg>=0.4.8\",\n    \"tyro>=0.6.0\", \"msgpack>=1.0.0\",\n])\n\n# Add repo to Python path\nsys.path.insert(0, REPO_DIR)\nos.chdir(REPO_DIR)\n\n# Verify import\nfrom src.configs import Config\nprint(f\"\\nEmergence Lab imported successfully from {REPO_DIR}\")\nprint(f\"Working directory: {os.getcwd()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Configuration\n#\n# MAXIMUM TRAINING RUN — uses full Kaggle weekly GPU budget (29 hours)\n# across multiple 12-hour sessions with auto-resume.\n#\n# This produces ~384,000 gradient updates (160x more than the initial test run).\n# Run the notebook 3 times: Session 1 (12h) → Session 2 (12h) → Session 3 (5h)\n# Each session auto-resumes from the latest checkpoint.\n\nfrom src.configs import (\n    Config,\n    EnvConfig,\n    FieldConfig,\n    AgentConfig,\n    TrainConfig,\n    LogConfig,\n    EvolutionConfig,\n    SpecializationConfig,\n    AnalysisConfig,\n)\n\n# --- Paths ---\nCHECKPOINT_DIR = \"/kaggle/working/checkpoints\"\nRESUME_FROM = None  # Auto-detected in Cell 4\n\n# --- Experiment Config ---\nconfig = Config(\n    env=EnvConfig(\n        grid_size=20,\n        num_agents=8,\n        num_food=20,       # More food for robust population\n        max_steps=500,\n    ),\n    field=FieldConfig(\n        num_channels=4,\n        diffusion_rate=0.1,\n        decay_rate=0.05,\n    ),\n    agent=AgentConfig(\n        hidden_dims=(64, 64),\n    ),\n    train=TrainConfig(\n        seed=42,\n        total_steps=1_600_000_000,  # 1.6B env steps = ~384K gradient updates = ~27 hours\n        num_envs=32,\n        num_steps=128,\n        learning_rate=3e-4,\n        resume_from=RESUME_FROM,\n    ),\n    log=LogConfig(\n        wandb=False,\n        save_interval=10_000_000,  # Save every 10M steps (~10 min, minimize data loss)\n        checkpoint_dir=CHECKPOINT_DIR,\n        server=False,\n    ),\n    analysis=AnalysisConfig(\n        emergence_check_interval=10_000,\n        specialization_check_interval=20_000,\n    ),\n    evolution=EvolutionConfig(\n        enabled=True,\n        starting_energy=200,\n        food_energy=100,\n        reproduce_threshold=120,\n        reproduce_cost=50,\n        mutation_std=0.01,\n        max_agents=32,\n    ),\n    specialization=SpecializationConfig(\n        diversity_bonus=0.1,\n        niche_pressure=0.05,\n    ),\n)\n\nprint(\"=\" * 60)\nprint(\"MAXIMUM TRAINING RUN — Phase 5 Data Collection\")\nprint(\"=\" * 60)\nprint(f\"  Grid: {config.env.grid_size}x{config.env.grid_size}\")\nprint(f\"  Agents: {config.env.num_agents} (max: {config.evolution.max_agents})\")\nprint(f\"  Food: {config.env.num_food}\")\nprint(f\"  Total steps: {config.train.total_steps:,} (~384K gradient updates)\")\nprint(f\"  Save interval: every {config.log.save_interval:,} steps (~10 min)\")\nprint(f\"  Checkpoint dir: {config.log.checkpoint_dir}\")\nprint(f\"  Evolution: enabled (mutation_std={config.evolution.mutation_std})\")\nprint(f\"  Diversity bonus: {config.specialization.diversity_bonus}\")\nprint(f\"  Niche pressure: {config.specialization.niche_pressure}\")\nprint(f\"  Estimated time: ~27 hours across 3 sessions\")\nprint(f\"  Resume from: {config.train.resume_from or 'Auto-detect in Cell 4'}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Resume or Start Fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Resume-or-start logic\n",
    "#\n",
    "# Automatically detects existing checkpoints and resumes if available.\n",
    "# If no checkpoint exists, starts fresh training.\n",
    "\n",
    "import os\n",
    "\n",
    "# Check for existing checkpoints\n",
    "latest_checkpoint = os.path.join(CHECKPOINT_DIR, \"latest.pkl\")\n",
    "\n",
    "if config.train.resume_from is not None:\n",
    "    # Explicit resume path set in Cell 3\n",
    "    if os.path.exists(config.train.resume_from):\n",
    "        print(f\"Will resume from explicit path: {config.train.resume_from}\")\n",
    "    else:\n",
    "        print(f\"WARNING: Resume path not found: {config.train.resume_from}\")\n",
    "        print(\"Will start fresh training.\")\n",
    "        config.train.resume_from = None\n",
    "elif os.path.exists(latest_checkpoint):\n",
    "    # Auto-detect latest checkpoint\n",
    "    config.train.resume_from = latest_checkpoint\n",
    "    print(f\"Found existing checkpoint: {latest_checkpoint}\")\n",
    "    print(\"Will resume from latest checkpoint.\")\n",
    "    \n",
    "    # Show checkpoint info\n",
    "    from src.training.checkpointing import load_checkpoint\n",
    "    ckpt = load_checkpoint(latest_checkpoint)\n",
    "    print(f\"  Checkpoint step: {ckpt.get('step', 'unknown')}\")\n",
    "    remaining = config.train.total_steps - ckpt.get('step', 0)\n",
    "    print(f\"  Remaining steps: {remaining:,}\")\n",
    "    if remaining <= 0:\n",
    "        print(\"  Training already complete! Increase total_steps to continue.\")\n",
    "else:\n",
    "    print(\"No existing checkpoint found. Starting fresh training.\")\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "    print(f\"Checkpoint directory created: {CHECKPOINT_DIR}\")\n",
    "\n",
    "print(f\"\\nReady to train for {config.train.total_steps:,} total steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run training with progress display\n",
    "#\n",
    "# This cell runs the full training loop. Checkpoints are saved\n",
    "# every save_interval steps and on completion.\n",
    "#\n",
    "# If the Kaggle session times out, re-run the notebook.\n",
    "# Cell 4 will automatically detect the latest checkpoint and resume.\n",
    "\n",
    "import time\n",
    "\n",
    "from src.training.train import train\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Checkpoints will be saved to: {config.log.checkpoint_dir}\")\n",
    "print(f\"Save interval: every {config.log.save_interval:,} steps\")\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "try:\n",
    "    final_state = train(config)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTraining complete! Elapsed: {elapsed / 3600:.1f} hours\")\n",
    "except KeyboardInterrupt:\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTraining interrupted after {elapsed / 3600:.1f} hours\")\n",
    "    print(\"Emergency checkpoint should have been saved.\")\n",
    "except Exception as e:\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTraining failed after {elapsed / 3600:.1f} hours: {e}\")\n",
    "    print(\"Check the latest checkpoint in the checkpoint directory.\")\n",
    "    raise\n",
    "\n",
    "# List saved checkpoints\n",
    "import glob\n",
    "checkpoints = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"step_*.pkl\")))\n",
    "print(f\"\\nSaved checkpoints ({len(checkpoints)}):\")\n",
    "for cp in checkpoints:\n",
    "    size_mb = os.path.getsize(cp) / (1024 * 1024)\n",
    "    print(f\"  {os.path.basename(cp)} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nDownload checkpoints from: {CHECKPOINT_DIR}\")\n",
    "print(\"Use Kaggle Output tab or kaggle_download.sh to retrieve them.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}